{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"oUdMCotlpSWX","executionInfo":{"status":"ok","timestamp":1681096113632,"user_tz":-420,"elapsed":5915,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","from torchsummary import summary\n","from torch.nn import init"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["###Unet and Attention Unet"],"metadata":{"id":"to1xXiTOzx-u"}},{"cell_type":"code","metadata":{"id":"nBSNO_MRpdF_","executionInfo":{"status":"ok","timestamp":1681096113634,"user_tz":-420,"elapsed":21,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"source":["# https://github.com/miguelvr/dropblock/blob/master/dropblock/dropblock.py\n","class DropBlock2D(nn.Module):\n","    def __init__(self, drop_prob, block_size):\n","        super(DropBlock2D, self).__init__()\n","        self.drop_prob = drop_prob\n","        self.block_size = block_size\n","    def forward(self, x):\n","        # shape: (bsize, channels, height, width)\n","        assert x.dim() == 4, \\\n","            \"Expected input with 4 dimensions (bsize, channels, height, width)\"\n","        if not self.training or self.drop_prob == 0.:\n","            return x\n","        else:\n","            # get gamma value\n","            gamma = self.drop_prob / (self.block_size ** 2)\n","            # sample mask\n","            mask = (torch.rand(x.shape[0], *x.shape[2:], device= x.device) < gamma).float()\n","            # compute block mask\n","            block_mask = self._compute_block_mask(mask)\n","            # apply block mask\n","            out = x * block_mask[:, None, :, :]\n","            # scale output\n","            out = out * block_mask.numel() / block_mask.sum()\n","            return out\n","    def _compute_block_mask(self, mask):\n","        block_mask = F.max_pool2d(input=mask[:, None, :, :],\n","                                  kernel_size=(self.block_size, self.block_size),\n","                                  stride=(1, 1),\n","                                  padding=self.block_size // 2)\n","\n","        if self.block_size % 2 == 0:\n","            block_mask = block_mask[:, :, :-1, :-1]\n","        block_mask = 1 - block_mask.squeeze(1)\n","        return block_mask\n","\n","class DropBlock3D(DropBlock2D):\n","    def __init__(self, drop_prob, block_size):\n","        super(DropBlock3D, self).__init__(drop_prob, block_size)\n","    def forward(self, x):\n","        # shape: (bsize, channels, depth, height, width)\n","        assert x.dim() == 5, \\\n","            \"Expected input with 5 dimensions (bsize, channels, depth, height, width)\"\n","        if not self.training or self.drop_prob == 0.:\n","            return x\n","        else:\n","            # get gamma value\n","            gamma = self.drop_prob / (self.block_size ** 3)\n","            # sample mask\n","            mask = (torch.rand(x.shape[0], *x.shape[2:]) < gamma).float()\n","            # place mask on input device\n","            mask = mask.to(x.device)\n","            # compute block mask\n","            block_mask = self._compute_block_mask(mask)\n","            # apply block mask\n","            out = x * block_mask[:, None, :, :, :]\n","            # scale output\n","            out = out * block_mask.numel() / block_mask.sum()\n","            return out\n","    def _compute_block_mask(self, mask):\n","        block_mask = F.max_pool3d(input=mask[:, None, :, :, :],\n","                                  kernel_size=(self.block_size, self.block_size, self.block_size),\n","                                  stride=(1, 1, 1),\n","                                  padding=self.block_size // 2)\n","        if self.block_size % 2 == 0:\n","            block_mask = block_mask[:, :, :-1, :-1, :-1]\n","        block_mask = 1 - block_mask.squeeze(1)\n","        return block_mask"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2X14iVipeYy","executionInfo":{"status":"ok","timestamp":1681096113634,"user_tz":-420,"elapsed":20,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"source":["class conv_block(nn.Sequential):\n","    def __init__(self, ch_in, ch_out, kernel_size = 3, \n","                 padding = 1, drop_block=False, block_size = 1, drop_prob = 0):\n","        super().__init__()\n","        self.add_module(\"conv1\",nn.Conv2d(ch_in, ch_out, kernel_size, padding = padding,bias=False))\n","        self.add_module(\"bn1\", nn.BatchNorm2d(ch_out))\n","        self.add_module(\"relu1\", nn.ReLU(inplace=True))\n","        self.add_module(\"conv2\",nn.Conv2d(ch_out, ch_out, kernel_size, padding = padding,bias=False))\n","        if drop_block:\n","            self.add_module(\"drop_block\", DropBlock2D(block_size = block_size, drop_prob = drop_prob))\n","        self.add_module(\"bn2\", nn.BatchNorm2d(ch_out))\n","        self.add_module(\"relu2\", nn.ReLU(inplace=True))\n","\n","class up_conv(nn.Module):\n","    def __init__(self,ch_in,ch_out):\n","        super(up_conv,self).__init__()\n","        self.up = nn.Sequential(\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(ch_in,ch_out,kernel_size=2,stride=1,padding=\"same\",bias=False,),\n","\t\t    nn.BatchNorm2d(ch_out),\n","\t\t\tnn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self,x):\n","        x = self.up(x)\n","        return x\n","\n","class U_Net(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=2, drop_prob = 0):\n","        super(U_Net,self).__init__()\n","        \n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","        channel = 64\n","        self.Conv1 = conv_block(ch_in=img_ch,ch_out=channel)\n","        self.Conv2 = conv_block(ch_in=channel,ch_out=channel*2)\n","        self.Conv3 = conv_block(ch_in=channel*2,ch_out=channel*4)\n","        self.Conv4 = conv_block(ch_in=channel*4,ch_out=channel*8, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","        self.Conv5 = conv_block(ch_in=channel*8,ch_out=channel*16, drop_block=True, block_size = 3, drop_prob = drop_prob)\n","\n","        self.Up5 = up_conv(ch_in=channel*16,ch_out=channel*8)\n","        self.Up_conv5 = conv_block(ch_in=channel*16, ch_out=channel*8)\n","\n","        self.Up4 = up_conv(ch_in=channel*8,ch_out=channel*4)\n","        self.Up_conv4 = conv_block(ch_in=channel*8, ch_out=channel*4)\n","        \n","        self.Up3 = up_conv(ch_in=channel*4,ch_out=channel*2)\n","        self.Up_conv3 = conv_block(ch_in=channel*4, ch_out=channel*2)\n","        \n","        self.Up2 = up_conv(ch_in=channel*2,ch_out=channel)\n","        self.Up_conv2 = conv_block(ch_in=channel*2, ch_out=channel)\n","\n","        self.Conv_1x1 = nn.Sequential(\n","            nn.Conv2d(channel, output_ch,kernel_size=1,stride=1,padding=0), \n","            nn.Softmax(dim=1)\n","            )\n","\n","\n","    def forward(self,x):\n","        # encoding path\n","        x1 = self.Conv1(x)\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","        \n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","        d5 = torch.cat((x4,d5),dim=1)\n","        \n","        d5 = self.Up_conv5(d5)\n","        \n","        d4 = self.Up4(d5)\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(d4)\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","\n","        d1 = self.Conv_1x1(d2)\n","\n","        return d1\n","\n","class Attention_block(nn.Module):\n","    def __init__(self,F_g,F_l,F_int):\n","        super(Attention_block,self).__init__()\n","        self.W_g = nn.Sequential(\n","            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","            )\n","        \n","        self.W_x = nn.Sequential(\n","            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","        )\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(1),\n","            nn.Sigmoid()\n","        )\n","        \n","        self.relu = nn.ReLU(inplace=True)\n","        \n","    def forward(self,g,x):\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        psi = self.relu(g1+x1)\n","        psi = self.psi(psi)\n","\n","        return x*psi\n","\n","class AttU_Net(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=2, drop_prob=0):\n","        super(AttU_Net,self).__init__()\n","        \n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","\n","        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n","        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n","        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n","        self.Conv4 = conv_block(ch_in=256,ch_out=512, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","        self.Conv5 = conv_block(ch_in=512,ch_out=1024, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","\n","        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n","        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n","        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n","\n","        self.Up4 = up_conv(ch_in=512,ch_out=256)\n","        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n","        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n","        \n","        self.Up3 = up_conv(ch_in=256,ch_out=128)\n","        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n","        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n","        \n","        self.Up2 = up_conv(ch_in=128,ch_out=64)\n","        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n","        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n","\n","        self.Conv_1x1 = nn.Sequential(\n","            nn.Conv2d(64, output_ch, kernel_size=1,stride=1,padding=0), \n","            nn.Softmax(dim=1)\n","            )\n","\n","    def forward(self,x):\n","        # encoding path\n","        x1 = self.Conv1(x)\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","        \n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","        x4 = self.Att5(d5,x4)\n","        d5 = torch.cat((x4,d5),dim=1)        \n","        d5 = self.Up_conv5(d5)\n","        \n","        d4 = self.Up4(d5)\n","        x3 = self.Att4(d4,x3)\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(d4)\n","        x2 = self.Att3(d3,x2)\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        x1 = self.Att2(d2,x1)\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","\n","        d1 = self.Conv_1x1(d2)\n","\n","        return d1\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmiuMlLPpkHS","executionInfo":{"status":"ok","timestamp":1681096113635,"user_tz":-420,"elapsed":20,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"source":["# summary(AttU_Net(), (3,192,256))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["###Double Unet"],"metadata":{"id":"X4f3wHkez3GO"}},{"cell_type":"code","metadata":{"id":"2w2N89XDWTfg","executionInfo":{"status":"ok","timestamp":1681096113635,"user_tz":-420,"elapsed":17,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"source":["# Pooling \n","class Squeeze_Excite(nn.Module):\n","    \n","    def __init__(self,channel,reduction):\n","        super().__init__()\n","        self.avgpool = nn.AdaptiveAvgPool2d(1)\n","        self.fc = nn.Sequential(\n","            nn.Linear(channel, channel // reduction, bias=False),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(channel // reduction, channel, bias=False),\n","            nn.Sigmoid()\n","        )\n","    \n","    def forward(self,x):\n","        b, c, _, _ = x.size()\n","        y = self.avgpool(x).view(b, c)\n","        y = self.fc(y).view(b, c, 1, 1)\n","        return x * y.expand_as(x)\n","        \n","# VGG block\n","class VGGBlock(nn.Module):\n","    \n","    def __init__(self, in_channels, middle_channels, out_channels):\n","        super().__init__()\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(middle_channels)\n","        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.SE = Squeeze_Excite(out_channels,8)\n","    \n","    def forward(self,x):\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        \n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.SE(out)\n","        \n","        return(out)"],"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def output_block():\n","    Layer = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=2, kernel_size=(1,1)),\n","                 nn.Sigmoid())\n","    return Layer"],"metadata":{"id":"emAVKwQ2NWOK","executionInfo":{"status":"ok","timestamp":1681096113635,"user_tz":-420,"elapsed":16,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class DUNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = VGGBlock(3,64,64)        \n","        self.conv2 = VGGBlock(64,128,128)\n","        self.conv3 = VGGBlock(128,256,256)\n","        self.conv4 = VGGBlock(256,512,512)\n","        self.conv5 = VGGBlock(512,512,512)\n","        \n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.up = nn.Upsample(scale_factor=2, mode='bilinear')\n","        \n","        self.Vgg1 = VGGBlock(1024,256,256)\n","        self.Vgg2 = VGGBlock(512,128,128)\n","        self.Vgg3 = VGGBlock(256,64,64)\n","        self.Vgg4 = VGGBlock(128,32,32)\n","        \n","        self.out = output_block()\n","        \n","        self.conv11 = VGGBlock(5,32,32)\n","        self.conv12 = VGGBlock(32,64,64)\n","        self.conv13 = VGGBlock(64,128,128)\n","        self.conv14 = VGGBlock(128,256,256)\n","        \n","        self.Vgg5 = VGGBlock(1024,256,256)\n","        self.Vgg6 = VGGBlock(640,128,128)\n","        self.Vgg7 = VGGBlock(320,64,64)\n","        self.Vgg8 = VGGBlock(160,32,32)\n","        \n","        self.out1 = nn.Conv2d(in_channels=32, out_channels=2, kernel_size=(1,1))\n","    \n","    def forward(self,x):\n","        x1 = self.conv1(x)\n","                \n","        x2 = self.conv2(self.pool(x1))\n","        x3 = self.conv3(self.pool(x2))\n","        x4 = self.conv4(self.pool(x3))\n","        x5 = self.conv5(self.pool(x4))        \n","        \n","        x5 = self.up(x5)\n","        x5 = torch.cat([x5,x4],1)\n","        x6 = self.Vgg1(x5)\n","        \n","        x6 = self.up(x6)\n","        x6 = torch.cat([x6,x3],1)  \n","        x7 = self.Vgg2(x6)\n","        x7 = self.up(x7)\n","        x7 = torch.cat([x7,x2],1)  \n","        x8 = self.Vgg3(x7)\n","                \n","        x8 = self.up(x8)\n","        x8 = torch.cat([x8,x1],1)  \n","        x9 = self.Vgg4(x8)\n","                \n","        output1 = self.out(x9)\n","        #print(output1.shape)\n","        #print(x.shape)\n","        output1 = x[:, :2, :, :] * output1\n","        \n","        x = torch.cat([x,output1],1)\n","        \n","        x11 = self.conv11(x)\n","                \n","        x12 = self.conv12(self.pool(x11))\n","        x13 = self.conv13(self.pool(x12))\n","        x14 = self.conv14(self.pool(x13))     \n","        \n","        y = self.pool(x14)\n","        \n","        y = self.up(y)\n","        y = torch.cat([y,x14,x4],1)\n","        y = self.Vgg5(y)\n","                \n","        y = self.up(y)\n","        y = torch.cat([y,x13,x3],1)\n","        y = self.Vgg6(y)\n","               \n","        y = self.up(y)\n","        y = torch.cat([y,x12,x2],1)\n","        y = self.Vgg7(y)\n","                \n","        y = self.up(y)\n","        y = torch.cat([y,x11,x1],1)\n","        y = self.Vgg8(y)\n","        \n","        output2 = self.out1(y)\n","\n","        #print(output2)\n","        return output2\n","\n"],"metadata":{"id":"p3gozdRBNZh-","executionInfo":{"status":"ok","timestamp":1681096113635,"user_tz":-420,"elapsed":13,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["x = torch.rand(1,3,192,256)\n","model = DUNet()\n","print(model(x).shape)"],"metadata":{"id":"oJ9aM1J8MyrG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681096116890,"user_tz":-420,"elapsed":3262,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}},"outputId":"500b2365-bbdc-400f-a1b9-42f13978391d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2, 192, 256])\n"]}]},{"cell_type":"markdown","source":["###Segnet"],"metadata":{"id":"uIO3iDZHz6eS"}},{"cell_type":"code","source":["class SegNet(nn.Module):\n","\n","\tdef __init__(self, BN_momentum=0.9):\n","\t\tsuper(SegNet, self).__init__()\n","\n","\t\t#SegNet Architecture\n","\t\t#Takes input of size in_chn = 3 (RGB images have 3 channels)\n","\t\t#Outputs size label_chn (N # of classes)\n","\n","\t\t#ENCODING consists of 5 stages\n","\t\t#Stage 1, 2 has 2 layers of Convolution + Batch Normalization + Max Pool respectively\n","\t\t#Stage 3, 4, 5 has 3 layers of Convolution + Batch Normalization + Max Pool respectively\n","\n","\t\t#General Max Pool 2D for ENCODING layers\n","\t\t#Pooling indices are stored for Upsampling in DECODING layers\n","\n","\t\tself.in_chn = 3\n","\t\tself.out_chn = 2\n","\n","\t\tself.MaxEn = nn.MaxPool2d(2, stride=2, return_indices=True) \n","\n","\t\tself.ConvEn11 = nn.Conv2d(self.in_chn, 64, kernel_size=3, padding=1)\n","\t\tself.BNEn11 = nn.BatchNorm2d(64, momentum=BN_momentum)\n","\t\tself.ConvEn12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","\t\tself.BNEn12 = nn.BatchNorm2d(64, momentum=BN_momentum)\n","\n","\t\tself.ConvEn21 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","\t\tself.BNEn21 = nn.BatchNorm2d(128, momentum=BN_momentum)\n","\t\tself.ConvEn22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","\t\tself.BNEn22 = nn.BatchNorm2d(128, momentum=BN_momentum)\n","\n","\t\tself.ConvEn31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n","\t\tself.BNEn31 = nn.BatchNorm2d(256, momentum=BN_momentum)\n","\t\tself.ConvEn32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","\t\tself.BNEn32 = nn.BatchNorm2d(256, momentum=BN_momentum)\n","\t\tself.ConvEn33 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","\t\tself.BNEn33 = nn.BatchNorm2d(256, momentum=BN_momentum)\n","\n","\t\tself.ConvEn41 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n","\t\tself.BNEn41 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\t\tself.ConvEn42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","\t\tself.BNEn42 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\t\tself.ConvEn43 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","\t\tself.BNEn43 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\n","\t\tself.ConvEn51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","\t\tself.BNEn51 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\t\tself.ConvEn52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","\t\tself.BNEn52 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\t\tself.ConvEn53 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","\t\tself.BNEn53 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\n","\n","\t\t#DECODING consists of 5 stages\n","\t\t#Each stage corresponds to their respective counterparts in ENCODING\n","\n","\t\t#General Max Pool 2D/Upsampling for DECODING layers\n","\t\tself.MaxDe = nn.MaxUnpool2d(2, stride=2) \n","\n","\t\tself.ConvDe53 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","\t\tself.BNDe53 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\t\tself.ConvDe52 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","\t\tself.BNDe52 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\t\tself.ConvDe51 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","\t\tself.BNDe51 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\n","\t\tself.ConvDe43 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","\t\tself.BNDe43 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\t\tself.ConvDe42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","\t\tself.BNDe42 = nn.BatchNorm2d(512, momentum=BN_momentum)\n","\t\tself.ConvDe41 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n","\t\tself.BNDe41 = nn.BatchNorm2d(256, momentum=BN_momentum)\n","\n","\t\tself.ConvDe33 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","\t\tself.BNDe33 = nn.BatchNorm2d(256, momentum=BN_momentum)\n","\t\tself.ConvDe32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","\t\tself.BNDe32 = nn.BatchNorm2d(256, momentum=BN_momentum)\n","\t\tself.ConvDe31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n","\t\tself.BNDe31 = nn.BatchNorm2d(128, momentum=BN_momentum)\n","\n","\t\tself.ConvDe22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","\t\tself.BNDe22 = nn.BatchNorm2d(128, momentum=BN_momentum)\n","\t\tself.ConvDe21 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n","\t\tself.BNDe21 = nn.BatchNorm2d(64, momentum=BN_momentum)\n","\n","\t\tself.ConvDe12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","\t\tself.BNDe12 = nn.BatchNorm2d(64, momentum=BN_momentum)\n","\t\tself.ConvDe11 = nn.Conv2d(64, self.out_chn, kernel_size=3, padding=1)\n","\t\tself.BNDe11 = nn.BatchNorm2d(self.out_chn, momentum=BN_momentum)\n","\n","\tdef forward(self, x):\n","\n","\t\t#ENCODE LAYERS\n","\t\t#Stage 1\n","\t\tx = F.relu(self.BNEn11(self.ConvEn11(x))) \n","\t\tx = F.relu(self.BNEn12(self.ConvEn12(x))) \n","\t\tx, ind1 = self.MaxEn(x)\n","\t\tsize1 = x.size()\n","\n","\t\t#Stage 2\n","\t\tx = F.relu(self.BNEn21(self.ConvEn21(x))) \n","\t\tx = F.relu(self.BNEn22(self.ConvEn22(x))) \n","\t\tx, ind2 = self.MaxEn(x)\n","\t\tsize2 = x.size()\n","\n","\t\t#Stage 3\n","\t\tx = F.relu(self.BNEn31(self.ConvEn31(x))) \n","\t\tx = F.relu(self.BNEn32(self.ConvEn32(x))) \n","\t\tx = F.relu(self.BNEn33(self.ConvEn33(x))) \t\n","\t\tx, ind3 = self.MaxEn(x)\n","\t\tsize3 = x.size()\n","\n","\t\t#Stage 4\n","\t\tx = F.relu(self.BNEn41(self.ConvEn41(x))) \n","\t\tx = F.relu(self.BNEn42(self.ConvEn42(x))) \n","\t\tx = F.relu(self.BNEn43(self.ConvEn43(x))) \t\n","\t\tx, ind4 = self.MaxEn(x)\n","\t\tsize4 = x.size()\n","\n","\t\t#Stage 5\n","\t\tx = F.relu(self.BNEn51(self.ConvEn51(x))) \n","\t\tx = F.relu(self.BNEn52(self.ConvEn52(x))) \n","\t\tx = F.relu(self.BNEn53(self.ConvEn53(x))) \t\n","\t\tx, ind5 = self.MaxEn(x)\n","\t\tsize5 = x.size()\n","\n","\t\t#DECODE LAYERS\n","\t\t#Stage 5\n","\t\tx = self.MaxDe(x, ind5, output_size=size4)\n","\t\tx = F.relu(self.BNDe53(self.ConvDe53(x)))\n","\t\tx = F.relu(self.BNDe52(self.ConvDe52(x)))\n","\t\tx = F.relu(self.BNDe51(self.ConvDe51(x)))\n","\n","\t\t#Stage 4\n","\t\tx = self.MaxDe(x, ind4, output_size=size3)\n","\t\tx = F.relu(self.BNDe43(self.ConvDe43(x)))\n","\t\tx = F.relu(self.BNDe42(self.ConvDe42(x)))\n","\t\tx = F.relu(self.BNDe41(self.ConvDe41(x)))\n","\n","\t\t#Stage 3\n","\t\tx = self.MaxDe(x, ind3, output_size=size2)\n","\t\tx = F.relu(self.BNDe33(self.ConvDe33(x)))\n","\t\tx = F.relu(self.BNDe32(self.ConvDe32(x)))\n","\t\tx = F.relu(self.BNDe31(self.ConvDe31(x)))\n","\n","\t\t#Stage 2\n","\t\tx = self.MaxDe(x, ind2, output_size=size1)\n","\t\tx = F.relu(self.BNDe22(self.ConvDe22(x)))\n","\t\tx = F.relu(self.BNDe21(self.ConvDe21(x)))\n","\n","\t\t#Stage 1\n","\t\tx = self.MaxDe(x, ind1)\n","\t\tx = F.relu(self.BNDe12(self.ConvDe12(x)))\n","\t\tx = self.ConvDe11(x)\n","\t\t#print (x)\n","\t\treturn x"],"metadata":{"id":"LkRiU46iRQ35","executionInfo":{"status":"ok","timestamp":1681096116891,"user_tz":-420,"elapsed":14,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#x = torch.rand(1,3,192,256)\n","#model = SegNet()\n","#print(model(x).shape)"],"metadata":{"id":"225wG1YiO00M","executionInfo":{"status":"ok","timestamp":1681096116892,"user_tz":-420,"elapsed":15,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["###TransUnet\n","\n","\n"],"metadata":{"id":"Vpxec2n6z-rs"}},{"cell_type":"code","source":["!pip install einops==0.3.0\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","from einops import rearrange, repeat\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, embedding_dim, head_num):\n","        super().__init__()\n","\n","        self.head_num = head_num\n","        self.dk = (embedding_dim // head_num) ** 1 / 2\n","\n","        self.qkv_layer = nn.Linear(embedding_dim, embedding_dim * 3, bias=False)\n","        self.out_attention = nn.Linear(embedding_dim, embedding_dim, bias=False)\n","\n","    def forward(self, x, mask=None):\n","        qkv = self.qkv_layer(x)\n","\n","        query, key, value = tuple(rearrange(qkv, 'b t (d k h ) -> k b h t d ', k=3, h=self.head_num))\n","        energy = torch.einsum(\"... i d , ... j d -> ... i j\", query, key) * self.dk\n","\n","        if mask is not None:\n","            energy = energy.masked_fill(mask, -np.inf)\n","\n","        attention = torch.softmax(energy, dim=-1)\n","\n","        x = torch.einsum(\"... i j , ... j d -> ... i d\", attention, value)\n","\n","        x = rearrange(x, \"b h t d -> b t (h d)\")\n","        x = self.out_attention(x)\n","\n","        return x\n","\n","\n","class MLP(nn.Module):\n","    def __init__(self, embedding_dim, mlp_dim):\n","        super().__init__()\n","\n","        self.mlp_layers = nn.Sequential(\n","            nn.Linear(embedding_dim, mlp_dim),\n","            nn.GELU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(mlp_dim, embedding_dim),\n","            nn.Dropout(0.1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.mlp_layers(x)\n","\n","        return x\n","\n","\n","class TransformerEncoderBlock(nn.Module):\n","    def __init__(self, embedding_dim, head_num, mlp_dim):\n","        super().__init__()\n","\n","        self.multi_head_attention = MultiHeadAttention(embedding_dim, head_num)\n","        self.mlp = MLP(embedding_dim, mlp_dim)\n","\n","        self.layer_norm1 = nn.LayerNorm(embedding_dim)\n","        self.layer_norm2 = nn.LayerNorm(embedding_dim)\n","\n","        self.dropout = nn.Dropout(0.1)\n","\n","    def forward(self, x):\n","        _x = self.multi_head_attention(x)\n","        _x = self.dropout(_x)\n","        x = x + _x\n","        x = self.layer_norm1(x)\n","\n","        _x = self.mlp(x)\n","        x = x + _x\n","        x = self.layer_norm2(x)\n","\n","        return x\n","\n","\n","class TransformerEncoder(nn.Module):\n","    def __init__(self, embedding_dim, head_num, mlp_dim, block_num=12):\n","        super().__init__()\n","\n","        self.layer_blocks = nn.ModuleList(\n","            [TransformerEncoderBlock(embedding_dim, head_num, mlp_dim) for _ in range(block_num)])\n","\n","    def forward(self, x):\n","        for layer_block in self.layer_blocks:\n","            x = layer_block(x)\n","\n","        return x\n","\n","\n","class ViT(nn.Module):\n","    def __init__(self, img_dim, in_channels, embedding_dim, head_num, mlp_dim,\n","                 block_num, patch_dim, classification=True, num_classes=1):\n","        super().__init__()\n","\n","        self.patch_dim = patch_dim\n","        self.classification = classification\n","        self.num_tokens = (img_dim // patch_dim) ** 2\n","        self.token_dim = in_channels * (patch_dim ** 2)\n","\n","        self.projection = nn.Linear(self.token_dim, embedding_dim)\n","        self.embedding = nn.Parameter(torch.rand(self.num_tokens + 1, embedding_dim))\n","\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, embedding_dim))\n","\n","        self.dropout = nn.Dropout(0.1)\n","\n","        self.transformer = TransformerEncoder(embedding_dim, head_num, mlp_dim, block_num)\n","\n","        if self.classification:\n","            self.mlp_head = nn.Linear(embedding_dim, num_classes)\n","\n","    def forward(self, x):\n","        img_patches = rearrange(x,\n","                                'b c (patch_x x) (patch_y y) -> b (x y) (patch_x patch_y c)',\n","                                patch_x=self.patch_dim, patch_y=self.patch_dim)\n","\n","        batch_size, tokens, _ = img_patches.shape\n","\n","        project = self.projection(img_patches)\n","        token = repeat(self.cls_token, 'b ... -> (b batch_size) ...',\n","                       batch_size=batch_size)\n","\n","        patches = torch.cat([token, project], dim=1)\n","        patches += self.embedding[:tokens + 1, :]\n","\n","        x = self.dropout(patches)\n","        x = self.transformer(x)\n","        x = self.mlp_head(x[:, 0, :]) if self.classification else x[:, 1:, :]\n","\n","        return x\n","\n","class EncoderBottleneck(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1, base_width=64):\n","        super().__init__()\n","\n","        self.downsample = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","\n","        width = int(out_channels * (base_width / 64))\n","\n","        self.conv1 = nn.Conv2d(in_channels, width, kernel_size=1, stride=1, bias=False)\n","        self.norm1 = nn.BatchNorm2d(width)\n","\n","        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=2, groups=1, padding=1, dilation=1, bias=False)\n","        self.norm2 = nn.BatchNorm2d(width)\n","\n","        self.conv3 = nn.Conv2d(width, out_channels, kernel_size=1, stride=1, bias=False)\n","        self.norm3 = nn.BatchNorm2d(out_channels)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        x_down = self.downsample(x)\n","\n","        x = self.conv1(x)\n","        x = self.norm1(x)\n","        x = self.relu(x)\n","\n","        x = self.conv2(x)\n","        x = self.norm2(x)\n","        x = self.relu(x)\n","\n","        x = self.conv3(x)\n","        x = self.norm3(x)\n","        x = x + x_down\n","        x = self.relu(x)\n","\n","        return x\n","\n","\n","class DecoderBottleneck(nn.Module):\n","    def __init__(self, in_channels, out_channels, scale_factor=2):\n","        super().__init__()\n","\n","        self.upsample = nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners=True)\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x, x_concat=None):\n","        x = self.upsample(x)\n","\n","        if x_concat is not None:\n","            x = torch.cat([x_concat, x], dim=1)\n","\n","        x = self.layer(x)\n","        return x\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, img_dim, in_channels, out_channels, head_num, mlp_dim, block_num, patch_dim):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.norm1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.encoder1 = EncoderBottleneck(out_channels, out_channels * 2, stride=2)\n","        self.encoder2 = EncoderBottleneck(out_channels * 2, out_channels * 4, stride=2)\n","        self.encoder3 = EncoderBottleneck(out_channels * 4, out_channels * 8, stride=2)\n","\n","        self.vit_img_dim = img_dim // patch_dim\n","        self.vit = ViT(self.vit_img_dim, out_channels * 8, out_channels * 8,\n","                       head_num, mlp_dim, block_num, patch_dim=1, classification=False)\n","\n","        self.conv2 = nn.Conv2d(out_channels * 8, 512, kernel_size=3, stride=1, padding=1)\n","        self.norm2 = nn.BatchNorm2d(512)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.norm1(x)\n","        x1 = self.relu(x)\n","\n","        x2 = self.encoder1(x1)\n","        x3 = self.encoder2(x2)\n","        x = self.encoder3(x3)\n","\n","        x = self.vit(x)\n","        x = rearrange(x, \"b (x y) c -> b c x y\", x=self.vit_img_dim, y=self.vit_img_dim)\n","\n","        x = self.conv2(x)\n","        x = self.norm2(x)\n","        x = self.relu(x)\n","\n","        return x, x1, x2, x3\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, out_channels, class_num):\n","        super().__init__()\n","\n","        self.decoder1 = DecoderBottleneck(out_channels * 8, out_channels * 2)\n","        self.decoder2 = DecoderBottleneck(out_channels * 4, out_channels)\n","        self.decoder3 = DecoderBottleneck(out_channels * 2, int(out_channels * 1 / 2))\n","        self.decoder4 = DecoderBottleneck(int(out_channels * 1 / 2), int(out_channels * 1 / 8))\n","\n","        self.conv1 = nn.Conv2d(int(out_channels * 1 / 8), class_num, kernel_size=1)\n","\n","    def forward(self, x, x1, x2, x3):\n","        x = self.decoder1(x, x3)\n","        x = self.decoder2(x, x2)\n","        x = self.decoder3(x, x1)\n","        x = self.decoder4(x)\n","        x = self.conv1(x)\n","\n","        return x\n","\n","\n","class TransUNet(nn.Module):\n","    def __init__(self, img_dim, in_channels, out_channels, head_num, mlp_dim, block_num, patch_dim, class_num):\n","        super().__init__()\n","\n","        self.encoder = Encoder(img_dim, in_channels, out_channels,\n","                               head_num, mlp_dim, block_num, patch_dim)\n","\n","        self.decoder = Decoder(out_channels, class_num)\n","\n","    def forward(self, x):\n","        x, x1, x2, x3 = self.encoder(x)\n","        x = self.decoder(x, x1, x2, x3)\n","\n","        return x\n"],"metadata":{"id":"VP1Y2icF0TIs","executionInfo":{"status":"ok","timestamp":1681096130661,"user_tz":-420,"elapsed":13783,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0494505a-3867-4ea7-ffbd-0329dc965c74"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting einops==0.3.0\n","  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n","Installing collected packages: einops\n","Successfully installed einops-0.3.0\n"]}]},{"cell_type":"code","source":["transunet = TransUNet(img_dim=128,\n","                          in_channels=3,\n","                          out_channels=128,\n","                          head_num=4,\n","                          mlp_dim=512,\n","                          block_num=8,\n","                          patch_dim=16,\n","                          class_num=2)\n","\n","print(sum(p.numel() for p in transunet.parameters()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"muQWDONx3vRt","executionInfo":{"status":"ok","timestamp":1681096131660,"user_tz":-420,"elapsed":1003,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}},"outputId":"80062218-ab7a-4081-ec20-59ac4925286b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["66882690\n"]}]},{"cell_type":"code","source":["#x = torch.rand(1,3,192,256)\n","#model = SegNet()\n","#print(transunet(x).shape)"],"metadata":{"id":"VXTh5U2p32ec","executionInfo":{"status":"ok","timestamp":1681096131661,"user_tz":-420,"elapsed":12,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["###CMUnet"],"metadata":{"id":"yMyqRgReInPb"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","import torch.nn as nn\n","import torch\n","\n","\n","class MSAG(nn.Module):\n","    \"\"\"\n","    Multi-scale attention gate\n","    \"\"\"\n","    def __init__(self, channel):\n","        super(MSAG, self).__init__()\n","        self.channel = channel\n","        self.pointwiseConv = nn.Sequential(\n","            nn.Conv2d(self.channel, self.channel, kernel_size=1, padding=0, bias=True),\n","            nn.BatchNorm2d(self.channel),\n","        )\n","        self.ordinaryConv = nn.Sequential(\n","            nn.Conv2d(self.channel, self.channel, kernel_size=3, padding=1, stride=1, bias=True),\n","            nn.BatchNorm2d(self.channel),\n","        )\n","        self.dilationConv = nn.Sequential(\n","            nn.Conv2d(self.channel, self.channel, kernel_size=3, padding=2, stride=1, dilation=2, bias=True),\n","            nn.BatchNorm2d(self.channel),\n","        )\n","        self.voteConv = nn.Sequential(\n","            nn.Conv2d(self.channel * 3, self.channel, kernel_size=(1, 1)),\n","            nn.BatchNorm2d(self.channel),\n","            nn.Sigmoid()\n","        )\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        x1 = self.pointwiseConv(x)\n","        x2 = self.ordinaryConv(x)\n","        x3 = self.dilationConv(x)\n","        _x = self.relu(torch.cat((x1, x2, x3), dim=1))\n","        _x = self.voteConv(_x)\n","        x = x + x * _x\n","        return x\n","\n","class Residual(nn.Module):\n","    def __init__(self, fn):\n","        super().__init__()\n","        self.fn = fn\n","\n","    def forward(self, x):\n","        return self.fn(x) + x\n","\n","\n","class ConvMixerBlock(nn.Module):\n","    def __init__(self, dim=1024, depth=7, k=7):\n","        super(ConvMixerBlock, self).__init__()\n","        self.block = nn.Sequential(\n","            *[nn.Sequential(\n","                Residual(nn.Sequential(\n","                    # deep wise\n","                    nn.Conv2d(dim, dim, kernel_size=(k, k), groups=dim, padding=(k // 2, k // 2)),\n","                    nn.GELU(),\n","                    nn.BatchNorm2d(dim)\n","                )),\n","                nn.Conv2d(dim, dim, kernel_size=(1, 1)),\n","                nn.GELU(),\n","                nn.BatchNorm2d(dim)\n","            ) for i in range(depth)]\n","        )\n","\n","    def forward(self, x):\n","        x = self.block(x)\n","        return x\n","\n","\n","class conv_block(nn.Module):\n","    def __init__(self, ch_in, ch_out):\n","        super(conv_block, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(ch_out),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(ch_out),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        return x\n","\n","\n","class up_conv(nn.Module):\n","    def __init__(self, ch_in, ch_out):\n","        super(up_conv, self).__init__()\n","        self.up = nn.Sequential(\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(ch_out),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        x = self.up(x)\n","        return x\n","\n","\n","class CMUNet(nn.Module):\n","    def __init__(self, img_ch=3, output_ch=2, l=7, k=7):\n","        \"\"\"\n","        Args:\n","            img_ch : input channel.\n","            output_ch: output channel.\n","            l: number of convMixer layers\n","            k: kernal size of convMixer\n","        \"\"\"\n","        super(CMUNet, self).__init__()\n","\n","        # Encoder\n","        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.Conv1 = conv_block(ch_in=img_ch, ch_out=64)\n","        self.Conv2 = conv_block(ch_in=64, ch_out=128)\n","        self.Conv3 = conv_block(ch_in=128, ch_out=256)\n","        self.Conv4 = conv_block(ch_in=256, ch_out=512)\n","        self.Conv5 = conv_block(ch_in=512, ch_out=1024)\n","        self.ConvMixer = ConvMixerBlock(dim=1024, depth=l, k=k)\n","        # Decoder\n","        self.Up5 = up_conv(ch_in=1024, ch_out=512)\n","        self.Up_conv5 = conv_block(ch_in=512 * 2, ch_out=512)\n","        self.Up4 = up_conv(ch_in=512, ch_out=256)\n","        self.Up_conv4 = conv_block(ch_in=256 * 2, ch_out=256)\n","        self.Up3 = up_conv(ch_in=256, ch_out=128)\n","        self.Up_conv3 = conv_block(ch_in=128 * 2, ch_out=128)\n","        self.Up2 = up_conv(ch_in=128, ch_out=64)\n","        self.Up_conv2 = conv_block(ch_in=64 * 2, ch_out=64)\n","        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n","        # Skip-connection\n","        self.msag4 = MSAG(512)\n","        self.msag3 = MSAG(256)\n","        self.msag2 = MSAG(128)\n","        self.msag1 = MSAG(64)\n","\n","    def forward(self, x):\n","        x1 = self.Conv1(x)\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","\n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","        x5 = self.ConvMixer(x5)\n","\n","        x4 = self.msag4(x4)\n","        x3 = self.msag3(x3)\n","        x2 = self.msag2(x2)\n","        x1 = self.msag1(x1)\n","\n","        d5 = self.Up5(x5)\n","        d5 = torch.cat((x4, d5), dim=1)\n","        d5 = self.Up_conv5(d5)\n","\n","        d4 = self.Up4(d5)\n","        d4 = torch.cat((x3, d4), dim=1)\n","        d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(d4)\n","        d3 = torch.cat((x2, d3), dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        d2 = torch.cat((x1, d2), dim=1)\n","        d2 = self.Up_conv2(d2)\n","        d1 = self.Conv_1x1(d2)\n","        return d1\n"],"metadata":{"id":"DqkQNHbFIrCL","executionInfo":{"status":"ok","timestamp":1681096237796,"user_tz":-420,"elapsed":546,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["#x = torch.rand(1,3,192,256)\n","#model = CMUNet()\n","#print(model(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ccVP_1y2I2Bb","executionInfo":{"status":"ok","timestamp":1681096241947,"user_tz":-420,"elapsed":2615,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}},"outputId":"c6eba6b9-ea28-4b57-fe0c-49b6891428c7"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2, 192, 256])\n"]}]},{"cell_type":"markdown","source":["###R2UNET"],"metadata":{"id":"46avsT_NK92U"}},{"cell_type":"code","source":["#from __future__ import print_function, division\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data\n","import torch\n","\n","\n","class conv_block(nn.Module):\n","    \"\"\"\n","    Convolution Block \n","    \"\"\"\n","    def __init__(self, in_ch, out_ch):\n","        super(conv_block, self).__init__()\n","        \n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True))\n","\n","    def forward(self, x):\n","\n","        x = self.conv(x)\n","        return x\n","\n","\n","class up_conv(nn.Module):\n","    \"\"\"\n","    Up Convolution Block\n","    \"\"\"\n","    def __init__(self, in_ch, out_ch):\n","        super(up_conv, self).__init__()\n","        self.up = nn.Sequential(\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        x = self.up(x)\n","        return x\n","\n","class Recurrent_block(nn.Module):\n","    \"\"\"\n","    Recurrent Block for R2Unet_CNN\n","    \"\"\"\n","    def __init__(self, out_ch, t=2):\n","        super(Recurrent_block, self).__init__()\n","\n","        self.t = t\n","        self.out_ch = out_ch\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n","            nn.BatchNorm2d(out_ch),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        for i in range(self.t):\n","            if i == 0:\n","                x = self.conv(x)\n","            out = self.conv(x + x)\n","        return out\n","\n","\n","class RRCNN_block(nn.Module):\n","    \"\"\"\n","    Recurrent Residual Convolutional Neural Network Block\n","    \"\"\"\n","    def __init__(self, in_ch, out_ch, t=2):\n","        super(RRCNN_block, self).__init__()\n","\n","        self.RCNN = nn.Sequential(\n","            Recurrent_block(out_ch, t=t),\n","            Recurrent_block(out_ch, t=t)\n","        )\n","        self.Conv = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        x1 = self.Conv(x)\n","        x2 = self.RCNN(x1)\n","        out = x1 + x2\n","        return out\n","\n","\n","class R2U_Net(nn.Module):\n","    \"\"\"\n","    R2U-Unet implementation\n","    Paper: https://arxiv.org/abs/1802.06955\n","    \"\"\"\n","    def __init__(self, img_ch=3, output_ch=2, t=2):\n","        super(R2U_Net, self).__init__()\n","\n","        n1 = 64\n","        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n","\n","        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.Upsample = nn.Upsample(scale_factor=2)\n","\n","        self.RRCNN1 = RRCNN_block(img_ch, filters[0], t=t)\n","\n","        self.RRCNN2 = RRCNN_block(filters[0], filters[1], t=t)\n","\n","        self.RRCNN3 = RRCNN_block(filters[1], filters[2], t=t)\n","\n","        self.RRCNN4 = RRCNN_block(filters[2], filters[3], t=t)\n","\n","        self.RRCNN5 = RRCNN_block(filters[3], filters[4], t=t)\n","\n","        self.Up5 = up_conv(filters[4], filters[3])\n","        self.Up_RRCNN5 = RRCNN_block(filters[4], filters[3], t=t)\n","\n","        self.Up4 = up_conv(filters[3], filters[2])\n","        self.Up_RRCNN4 = RRCNN_block(filters[3], filters[2], t=t)\n","\n","        self.Up3 = up_conv(filters[2], filters[1])\n","        self.Up_RRCNN3 = RRCNN_block(filters[2], filters[1], t=t)\n","\n","        self.Up2 = up_conv(filters[1], filters[0])\n","        self.Up_RRCNN2 = RRCNN_block(filters[1], filters[0], t=t)\n","\n","        self.Conv = nn.Conv2d(filters[0], output_ch, kernel_size=1, stride=1, padding=0)\n","\n","       # self.active = torch.nn.Sigmoid()\n","\n","\n","    def forward(self, x):\n","\n","        e1 = self.RRCNN1(x)\n","\n","        e2 = self.Maxpool(e1)\n","        e2 = self.RRCNN2(e2)\n","\n","        e3 = self.Maxpool1(e2)\n","        e3 = self.RRCNN3(e3)\n","\n","        e4 = self.Maxpool2(e3)\n","        e4 = self.RRCNN4(e4)\n","\n","        e5 = self.Maxpool3(e4)\n","        e5 = self.RRCNN5(e5)\n","\n","        d5 = self.Up5(e5)\n","        d5 = torch.cat((e4, d5), dim=1)\n","        d5 = self.Up_RRCNN5(d5)\n","\n","        d4 = self.Up4(d5)\n","        d4 = torch.cat((e3, d4), dim=1)\n","        d4 = self.Up_RRCNN4(d4)\n","\n","        d3 = self.Up3(d4)\n","        d3 = torch.cat((e2, d3), dim=1)\n","        d3 = self.Up_RRCNN3(d3)\n","\n","        d2 = self.Up2(d3)\n","        d2 = torch.cat((e1, d2), dim=1)\n","        d2 = self.Up_RRCNN2(d2)\n","\n","        out = self.Conv(d2)\n","\n","      # out = self.active(out)\n","\n","        return out"],"metadata":{"id":"ORBap_Z5KVOB","executionInfo":{"status":"ok","timestamp":1681096680861,"user_tz":-420,"elapsed":348,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["#x = torch.rand(1,3,192,256)\n","#model = R2U_Net()\n","#print(model(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSN6-DaWKv8w","executionInfo":{"status":"ok","timestamp":1681096687708,"user_tz":-420,"elapsed":4604,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}},"outputId":"74fcc3ce-8ba7-4779-ce8e-d797e41f90da"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 2, 192, 256])\n"]}]}]}