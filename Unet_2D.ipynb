{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["xuKV86zyM5JE","EVXRyU12y8NE","fFbxa69CjjHb","ng3qPvlY9w0S","kEql7Bsw9105"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Libraries"],"metadata":{"id":"xuKV86zyM5JE"}},{"cell_type":"code","metadata":{"id":"5VxGrJjz9azU"},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","import torch.nn.functional as F\n","from torchsummary import summary\n","from torch.nn import init\n","from skimage import morphology as morph\n","import torch.utils.model_zoo as model_zoo\n","import math\n","#from skimage.morphology import watershed\n","from skimage.segmentation import find_boundaries\n","from scipy import ndimage\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EVXRyU12y8NE"},"source":["# Preparation"]},{"cell_type":"code","metadata":{"id":"meu_SynQIK4s"},"source":["# https://github.com/miguelvr/dropblock/blob/master/dropblock/dropblock.py\n","class DropBlock2D(nn.Module):\n","    def __init__(self, drop_prob, block_size):\n","        super(DropBlock2D, self).__init__()\n","        self.drop_prob = drop_prob\n","        self.block_size = block_size\n","    def forward(self, x):\n","        # shape: (bsize, channels, height, width)\n","        assert x.dim() == 4, \\\n","            \"Expected input with 4 dimensions (bsize, channels, height, width)\"\n","        if not self.training or self.drop_prob == 0.:\n","            return x\n","        else:\n","            # get gamma value\n","            gamma = self.drop_prob / (self.block_size ** 2)\n","            # sample mask\n","            mask = (torch.rand(x.shape[0], *x.shape[2:], device= x.device) < gamma).float()\n","            # compute block mask\n","            block_mask = self._compute_block_mask(mask)\n","            # apply block mask\n","            out = x * block_mask[:, None, :, :]\n","            # scale output\n","            out = out * block_mask.numel() / block_mask.sum()\n","            return out\n","    def _compute_block_mask(self, mask):\n","        block_mask = F.max_pool2d(input=mask[:, None, :, :],\n","                                  kernel_size=(self.block_size, self.block_size),\n","                                  stride=(1, 1),\n","                                  padding=self.block_size // 2)\n","\n","        if self.block_size % 2 == 0:\n","            block_mask = block_mask[:, :, :-1, :-1]\n","        block_mask = 1 - block_mask.squeeze(1)\n","        return block_mask\n","\n","class DropBlock3D(DropBlock2D):\n","    def __init__(self, drop_prob, block_size):\n","        super(DropBlock3D, self).__init__(drop_prob, block_size)\n","    def forward(self, x):\n","        # shape: (bsize, channels, depth, height, width)\n","        assert x.dim() == 5, \\\n","            \"Expected input with 5 dimensions (bsize, channels, depth, height, width)\"\n","        if not self.training or self.drop_prob == 0.:\n","            return x\n","        else:\n","            # get gamma value\n","            gamma = self.drop_prob / (self.block_size ** 3)\n","            # sample mask\n","            mask = (torch.rand(x.shape[0], *x.shape[2:]) < gamma).float()\n","            # place mask on input device\n","            mask = mask.to(x.device)\n","            # compute block mask\n","            block_mask = self._compute_block_mask(mask)\n","            # apply block mask\n","            out = x * block_mask[:, None, :, :, :]\n","            # scale output\n","            out = out * block_mask.numel() / block_mask.sum()\n","            return out\n","    def _compute_block_mask(self, mask):\n","        block_mask = F.max_pool3d(input=mask[:, None, :, :, :],\n","                                  kernel_size=(self.block_size, self.block_size, self.block_size),\n","                                  stride=(1, 1, 1),\n","                                  padding=self.block_size // 2)\n","        if self.block_size % 2 == 0:\n","            block_mask = block_mask[:, :, :-1, :-1, :-1]\n","        block_mask = 1 - block_mask.squeeze(1)\n","        return block_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4YtzETDt9LZx"},"source":["class CBAM(nn.Module):\n","    def __init__(self, in_channel, reduction_ratio = 8):\n","        super().__init__()\n","        self.hid_channel = max(1, in_channel // reduction_ratio)\n","        self.globalAvgPool = nn.AdaptiveAvgPool2d(1)\n","        self.globalMaxPool = nn.AdaptiveMaxPool2d(1)\n","        # Shared MLP.\n","        self.fc = nn.Sequential(nn.Conv2d(in_channel, self.hid_channel, 1, bias=False),\n","                               nn.Mish(),\n","                               nn.Conv2d(self.hid_channel, in_channel, 1, bias=False))\n","        self.sigmoid = nn.Sigmoid()\n","        self.conv1 = nn.Conv2d(2, 1, kernel_size=7,\n","                               stride=1, padding=3, bias=False)\n","    def forward(self, x):\n","        ''' Channel attention '''\n","        avgOut = self.fc(self.globalAvgPool(x))\n","        maxOut = self.fc(self.globalMaxPool(x))\n","        Mc = self.sigmoid(avgOut + maxOut)\n","        Mf1 = Mc * x\n","\n","        ''' Spatial attention. '''\n","        avg_out = torch.mean(Mf1, dim=1, keepdim=True)\n","        max_out, _ = torch.max(Mf1, dim=1, keepdim=True)\n","\n","        Ms = torch.cat([max_out, avg_out], dim=1)\n","        Ms = self.sigmoid(self.conv1(Ms))\n","        Mf2 = Ms * Mf1\n","        return Mf2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qaJr5QRJiv0C"},"source":["class ConvBn(nn.Sequential):\n","    def __init__(self, in_channel, out_channel, kernel_size = 3,\n","                 padding = 1, drop_block=False, block_size = 1, drop_prob = 0):\n","        super().__init__()\n","        self.add_module(\"conv\",nn.Conv2d(in_channel, out_channel, kernel_size, padding = padding,bias=False))\n","        if drop_block:\n","            self.add_module(\"drop_block\", DropBlock2D(block_size = block_size, drop_prob = drop_prob))\n","        self.add_module(\"bn\", nn.BatchNorm2d(out_channel))\n","        self.add_module(\"mish\", nn.Mish())\n","        self.add_module(\"cbam\", CBAM(out_channel))\n","\n","class DownSampleBlock(nn.Sequential):\n","    def __init__(self, in_channel, block_size = 1, drop_prob = 0):\n","        super().__init__()\n","        out_channel = in_channel // 2\n","        self.add_module(\"conv1\", nn.Conv2d(in_channel, out_channel, 1, bias=False))\n","        self.add_module(\"drop_block1\", DropBlock2D(block_size = block_size, drop_prob = drop_prob))\n","        self.add_module(\"bn\", nn.BatchNorm2d(out_channel))\n","        self.add_module(\"mish\", nn.Mish())\n","        self.add_module(\"cbam\", CBAM(out_channel))\n","        self.add_module(\"conv2\", nn.Conv2d(out_channel, out_channel, 2, 2, bias=False))\n","        self.add_module(\"drop_block2\", DropBlock2D(block_size = block_size, drop_prob = drop_prob))\n","\n","\n","class AttentionBlock(nn.Module):\n","    def __init__(self, in_channel, in_channel_skip, out_channel):\n","        super().__init__()\n","        self.conv_input = nn.Sequential(\n","            nn.Conv2d(in_channel, out_channel, 1, padding = 0, bias=False),\n","            nn.BatchNorm2d(out_channel),\n","            nn.ConvTranspose2d(out_channel, out_channel, 2, 2),\n","            CBAM(out_channel)\n","        )\n","        self.conv_skip = nn.Sequential(\n","            nn.Conv2d(in_channel_skip, out_channel, 1, bias = False),\n","            nn.BatchNorm2d(out_channel),\n","        )\n","        self.mixed_weight = nn.Sequential(\n","            nn.Mish(),\n","            nn.Conv2d(out_channel, 1, 1, bias = False),\n","            nn.BatchNorm2d(1),\n","            nn.Sigmoid()\n","        )\n","    def forward(self, x, skip):\n","        input_weight = self.conv_input(x)\n","        skip_weight = self.conv_skip(skip)\n","        output_weight = self.mixed_weight(input_weight + skip_weight)\n","        return output_weight * skip\n","\n","class DenseLayer(nn.Module):\n","    def __init__(self, in_channel, grow_rate):\n","        super().__init__()\n","        self.layer = nn.Sequential(\n","            ConvBn(in_channel, grow_rate*4,kernel_size=1, padding=0),\n","            ConvBn(grow_rate*4, grow_rate)\n","        )\n","    def forward(self, x):\n","        output = self.layer(x)\n","        return torch.cat([output, x], dim = 1)\n","\n","class DenseBlock(nn.Sequential):\n","    def __init__(self, in_channel, grow_rate, repetition):\n","        super().__init__()\n","        for i in range(repetition):\n","            layer = DenseLayer(in_channel+i*grow_rate, grow_rate)\n","            self.add_module(f\"dense_layer_{i+1}\", layer)\n","\n","class DecoderBlock(nn.Module):\n","    def __init__(self, in_channel, in_channel_skip, out_channel,\n","                 block_size = 1, drop_prob = 0):\n","        super().__init__()\n","        self.conv_trans = nn.ConvTranspose2d(in_channel, out_channel, 2, 2)\n","        self.attention = AttentionBlock(in_channel, in_channel_skip, out_channel)\n","        self.convbn = ConvBn(in_channel_skip + out_channel, out_channel, drop_block=True,\n","                            block_size = block_size, drop_prob = drop_prob)\n","\n","    def forward(self, x, skip):\n","        output = self.conv_trans(x)\n","        attention = self.attention(x, skip)\n","        output = torch.cat([output, attention], dim=1)\n","        return self.convbn(output)\n","\n","class UpsampleBlock(nn.Sequential):\n","    def __init__(self,  in_channel, out_channel, times):\n","        super().__init__()\n","        for i in range(times):\n","            channel = in_channel if i == 0 else out_channel\n","            self.add_module(f\"convtrans{i+1}\", nn.ConvTranspose2d(channel, out_channel, 2, 2))\n","            self.add_module(f\"cbam{i+1}\", CBAM(out_channel))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class conv_block(nn.Sequential):\n","    def __init__(self, ch_in, ch_out, kernel_size = 3,\n","                 padding = 1, drop_block=False, block_size = 1, drop_prob = 0):\n","        super().__init__()\n","        self.add_module(\"conv1\",nn.Conv2d(ch_in, ch_out, kernel_size, padding = padding,bias=False))\n","        self.add_module(\"bn1\", nn.BatchNorm2d(ch_out))\n","        self.add_module(\"relu1\", nn.ReLU(inplace=True))\n","        self.add_module(\"conv2\",nn.Conv2d(ch_out, ch_out, kernel_size, padding = padding,bias=False))\n","        if drop_block:\n","            self.add_module(\"drop_block\", DropBlock2D(block_size = block_size, drop_prob = drop_prob))\n","        self.add_module(\"bn2\", nn.BatchNorm2d(ch_out))\n","        self.add_module(\"relu2\", nn.ReLU(inplace=True))\n","\n","class up_conv(nn.Module):\n","    def __init__(self,ch_in,ch_out):\n","        super(up_conv,self).__init__()\n","        self.up = nn.Sequential(\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(ch_in,ch_out,kernel_size=2,stride=1,padding=\"same\",bias=False,),\n","\t\t    nn.BatchNorm2d(ch_out),\n","\t\t\tnn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self,x):\n","        x = self.up(x)\n","        return x"],"metadata":{"id":"VwtIK1LoByvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Residual(nn.Module):\n","    def __init__(self, fn):\n","        super().__init__()\n","        self.fn = fn\n","\n","    def forward(self, x):\n","        return self.fn(x) + x\n","\n","def ConvMixer(dim, depth, kernel_size=9, patch_size=7):\n","    return nn.Sequential(\n","        nn.Conv2d(dim, dim, kernel_size=patch_size, stride=patch_size),\n","        nn.GELU(),\n","        nn.BatchNorm2d(dim),\n","        *[nn.Sequential(\n","                Residual(nn.Sequential(\n","                    nn.Conv2d(dim, dim, (1, kernel_size), groups=dim, padding=\"same\"),\n","                    nn.GELU(),\n","                    nn.BatchNorm2d(dim),\n","                    nn.Conv2d(dim, dim, (kernel_size, 1), groups=dim, padding=\"same\"),\n","                    nn.GELU(),\n","                    nn.BatchNorm2d(dim)\n","                )),\n","                nn.Conv2d(dim, dim, kernel_size=1),\n","                nn.GELU(),\n","                nn.BatchNorm2d(dim)\n","        ) for i in range(depth)])\n","        #nn.AdaptiveAvgPool2d((1,1)),\n","        #nn.Flatten(),\n","        #nn.Linear(dim, n_classes))"],"metadata":{"id":"L02IukqDDYoY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Attention_block(nn.Module):\n","    def __init__(self,F_g,F_l,F_int):\n","        super(Attention_block,self).__init__()\n","        self.W_g = nn.Sequential(\n","            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","            )\n","\n","        self.W_x = nn.Sequential(\n","            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","        )\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(1),\n","            nn.Sigmoid()\n","        )\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self,g,x):\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        psi = self.relu(g1+x1)\n","        psi = self.psi(psi)\n","\n","        return x*psi"],"metadata":{"id":"Mwd7kxpkjeMh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''class Conv2d(nn.Module):\n","    def __init__(self, pdc, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\n","        super(Conv2d, self).__init__()\n","        if in_channels % groups != 0:\n","            raise ValueError('in_channels must be divisible by groups')\n","        if out_channels % groups != 0:\n","            raise ValueError('out_channels must be divisible by groups')\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.dilation = dilation\n","        self.groups = groups\n","        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size))\n","        if bias:\n","            self.bias = nn.Parameter(torch.Tensor(out_channels))\n","        else:\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","        self.pdc = pdc\n","\n","    def reset_parameters(self):\n","        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n","        if self.bias is not None:\n","            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n","            bound = 1 / math.sqrt(fan_in)\n","            nn.init.uniform_(self.bias, -bound, bound)\n","\n","    def forward(self, input):\n","\n","        return self.pdc(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)'''"],"metadata":{"id":"HAr58rQrrWsC","colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"status":"ok","timestamp":1682826110949,"user_tz":-420,"elapsed":21,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}},"outputId":"5d95240c-d5e4-4578-f54d-9550d0a2285d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"class Conv2d(nn.Module):\\n    def __init__(self, pdc, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False):\\n        super(Conv2d, self).__init__()\\n        if in_channels % groups != 0:\\n            raise ValueError('in_channels must be divisible by groups')\\n        if out_channels % groups != 0:\\n            raise ValueError('out_channels must be divisible by groups')\\n        self.in_channels = in_channels\\n        self.out_channels = out_channels\\n        self.kernel_size = kernel_size\\n        self.stride = stride\\n        self.padding = padding\\n        self.dilation = dilation\\n        self.groups = groups\\n        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size))\\n        if bias:\\n            self.bias = nn.Parameter(torch.Tensor(out_channels))\\n        else:\\n            self.register_parameter('bias', None)\\n        self.reset_parameters()\\n        self.pdc = pdc\\n\\n    def reset_parameters(self):\\n        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\\n        if self.bias is not None:\\n            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\\n            bound = 1 / math.sqrt(fan_in)\\n            nn.init.uniform_(self.bias, -bound, bound)\\n\\n    def forward(self, input):\\n\\n        return self.pdc(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["class _ASPPModule(nn.Module):\n","    def __init__(self, inplanes, planes, kernel_size, padding, dilation, BatchNorm):\n","        super().__init__()\n","        self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n","                                      stride=1, padding=padding, dilation=dilation, bias=False)\n","        self.bn = BatchNorm(planes)\n","        self.silu = nn.SiLU(inplace=True)\n","        self._init_weight()\n","\n","    def forward(self, x):\n","        x = self.atrous_conv(x)\n","        x = self.bn(x)\n","\n","        return self.silu(x)\n","\n","    def _init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                torch.nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class ASPP(nn.Module):\n","    def __init__(self, inplanes, outplanes, output_stride, BatchNorm):\n","        super().__init__()\n","        if output_stride == 4:\n","            dilations = [1, 6, 12, 18]\n","        elif output_stride == 8:\n","            dilations = [1, 4, 6, 10]\n","        elif output_stride == 2:\n","            dilations = [1, 12, 24, 36]\n","        else:\n","            raise NotImplementedError\n","\n","        #self.aspp1 = _ASPPModule(inplanes, outplanes, 1, padding=0,dilation=dilations[0], BatchNorm=BatchNorm)\n","        self.aspp2 = _ASPPModule(inplanes, outplanes, 3, padding=dilations[1], dilation=dilations[1], BatchNorm=BatchNorm)\n","        self.aspp3 = _ASPPModule(inplanes, outplanes, 3, padding=dilations[2], dilation=dilations[2], BatchNorm=BatchNorm)\n","        self.aspp4 = _ASPPModule(inplanes, outplanes, 3, padding=dilations[3], dilation=dilations[3], BatchNorm=BatchNorm)\n","\n","        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)),\n","                                             nn.Conv2d(inplanes, outplanes, 1, stride=1, bias=False),\n","                                             #BatchNorm(outplanes),\n","                                             nn.SiLU(inplace=True))\n","        self.conv1 = nn.Conv2d(outplanes*4, outplanes, 1, bias=False)\n","        self.bn1 = BatchNorm(outplanes)\n","        self.silu = nn.SiLU(inplace=True)\n","        self.dropout = nn.Dropout(0.0)\n","        self._init_weight()\n","\n","    def forward(self, x):\n","        #x1 = self.aspp1(x)\n","        x2 = self.aspp2(x)\n","        x3 = self.aspp3(x)\n","        x4 = self.aspp4(x)\n","        x5 = self.global_avg_pool(x)\n","        x5 = F.interpolate(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n","        x = torch.cat((x2, x3, x4, x5), dim=1)\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.silu(x)\n","\n","        return self.dropout(x)\n","\n","    def _init_weight(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                torch.nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","class PASPP(nn.Module):\n","    def __init__(self, inplanes, outplanes, output_stride=4, BatchNorm=nn.BatchNorm2d):\n","        super().__init__()\n","        if output_stride == 4:\n","            dilations = [1, 6, 12, 18]\n","        elif output_stride == 8:\n","            dilations = [1, 4, 6, 10]\n","        elif output_stride == 2:\n","            dilations = [1, 12, 24, 36]\n","        elif output_stride == 16:\n","            dilations = [1, 2, 3, 4]\n","        elif output_stride == 1:\n","            dilations = [1, 16, 32, 48]\n","        else:\n","            raise NotImplementedError\n","        self._norm_layer = BatchNorm\n","        self.silu = nn.SiLU(inplace=True)\n","        self.conv1 = self._make_layer(inplanes, inplanes // 4)\n","        self.conv2 = self._make_layer(inplanes, inplanes // 4)\n","        self.conv3 = self._make_layer(inplanes, inplanes // 4)\n","        self.conv4 = self._make_layer(inplanes, inplanes // 4)\n","        self.atrous_conv1 = nn.Conv2d(inplanes // 4, inplanes // 4, kernel_size=3, dilation=dilations[0], padding=dilations[0])\n","        self.atrous_conv2 = nn.Conv2d(inplanes // 4, inplanes // 4, kernel_size=3, dilation=dilations[1], padding=dilations[1])\n","        self.atrous_conv3 = nn.Conv2d(inplanes // 4, inplanes // 4, kernel_size=3, dilation=dilations[2], padding=dilations[2])\n","        self.atrous_conv4 = nn.Conv2d(inplanes // 4, inplanes // 4, kernel_size=3, dilation=dilations[3], padding=dilations[3])\n","        self.conv5 = self._make_layer(inplanes // 2, inplanes // 2)\n","        self.conv6 = self._make_layer(inplanes // 2, inplanes // 2)\n","        self.convout = self._make_layer(inplanes, inplanes)\n","\n","    def _make_layer(self, inplanes, outplanes):\n","        layer = []\n","        layer.append(nn.Conv2d(inplanes, outplanes, kernel_size = 1))\n","        layer.append(self._norm_layer(outplanes))\n","        layer.append(self.silu)\n","        return nn.Sequential(*layer)\n","\n","    def forward(self, X):\n","        x1 = self.conv1(X)\n","        x2 = self.conv2(X)\n","        x3 = self.conv3(X)\n","        x4 = self.conv4(X)\n","\n","        x12 = torch.add(x1, x2)\n","        x34 = torch.add(x3, x4)\n","\n","        x1 = torch.add(self.atrous_conv1(x1),x12)\n","        x2 = torch.add(self.atrous_conv2(x2),x12)\n","        x3 = torch.add(self.atrous_conv3(x3),x34)\n","        x4 = torch.add(self.atrous_conv4(x4),x34)\n","\n","        x12 = torch.cat([x1, x2], dim = 1)\n","        x34 = torch.cat([x3, x4], dim = 1)\n","\n","        x12 = self.conv5(x12)\n","        x34 = self.conv5(x34)\n","        x = torch.cat([x12, x34], dim=1)\n","        x = self.convout(x)\n","        return x"],"metadata":{"id":"iC3nOazVwaBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class activation_block(nn.Module):\n","  def __init__(self, outplane):\n","    super(activation_block, self).__init__()\n","    self.gelu = nn.GELU()\n","    self.outplane = outplane\n","    self.batchnorm = nn.BatchNorm2d(outplane)\n","\n","  def forward(self, x):\n","    x = self.gelu(x)\n","    x = self.batchnorm(x)\n","    return x\n","\n","class conv_stem(nn.Module):\n","  def __init__(self, inplane, outplane, patch_size):\n","    super(conv_stem, self).__init__()\n","    self.inplane = inplane\n","    self.outplane = outplane\n","    self.patch_size = patch_size\n","    self.conv = nn.Conv2d(self.inplane, self.outplane, kernel_size=self.patch_size, stride=self.patch_size)\n","    self.activation = activation_block(self.outplane)\n","\n","  def forward(self, x):\n","    x = self.conv(x)\n","    x = self.activation(x)\n","    return x\n","\n","class DepthwiseConv2d(nn.Module):\n","  def __init__(self, inplane, kernels_per_layer, outplane):\n","    super(DepthwiseConv2d, self).__init__()\n","    self.inplane = inplane\n","    self.outplane = outplane\n","    self.kernels_per_layer = kernels_per_layer\n","    self.depthwise = nn.Conv2d(self.inplane, self.inplane * self.kernels_per_layer, kernel_size=3, padding=1, groups=self.inplane)\n","    #self.pointwise = nn.Conv2d(nin * kernels_per_layer, nout, kernel_size=1)\n","\n","  def forward(self, x):\n","    out = self.depthwise(x)\n","    #out = self.pointwise(out)\n","    return out\n","\n","class ConvMixer(nn.Module):\n","  def __init__(self, inplane, kernels_per_layer, outplane, kernels_size):\n","    super(ConvMixer, self).__init__()\n","    self.inplane = inplane\n","    self.outplane = outplane\n","    self.kernels_per_layer = kernels_per_layer\n","    self.kernel_size = kernels_size\n","    self.depthwise = DepthwiseConv2d(self.inplane, self.kernels_per_layer, self.outplane)\n","    self.pointwise = nn.Conv2d(self.inplane * self.kernels_per_layer, self.outplane, kernel_size=1)\n","    self.activation = activation_block(self.outplane)\n","\n","  def forward(self, x):\n","    #Depthwise convolution\n","    x0 = x\n","    x = self.depthwise(x)\n","    x = x + x0 #Residual\n","\n","    #Pointwise convolution\n","    x = self.pointwise(x)\n","    x = self.activation(x)\n","    return x\n","\n","'''def get_conv_mixer_256_8(image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=10):\n","    inputs = keras.Input((image_size, image_size, 3))\n","    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n","\n","    # Extract patch embeddings.\n","    x = conv_stem(x, filters, patch_size)\n","\n","    # ConvMixer blocks.\n","    for _ in range(depth):\n","        x = conv_mixer_block(x, filters, kernel_size)\n","\n","    # Classification block.\n","    x = layers.GlobalAvgPool2D()(x)\n","    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n","\n","    return keras.Model(inputs, outputs)'''"],"metadata":{"id":"UFzNmTk2ZbH9","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1682826110950,"user_tz":-420,"elapsed":17,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}},"outputId":"557c6744-ebbd-4129-c47c-4ff8bb72b046"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def get_conv_mixer_256_8(image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=10):\\n    inputs = keras.Input((image_size, image_size, 3))\\n    x = layers.Rescaling(scale=1.0 / 255)(inputs)\\n\\n    # Extract patch embeddings.\\n    x = conv_stem(x, filters, patch_size)\\n\\n    # ConvMixer blocks.\\n    for _ in range(depth):\\n        x = conv_mixer_block(x, filters, kernel_size)\\n\\n    # Classification block.\\n    x = layers.GlobalAvgPool2D()(x)\\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\\n\\n    return keras.Model(inputs, outputs)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["class Residual(nn.Module):\n","    def __init__(self, fn):\n","        super().__init__()\n","        self.fn = fn\n","\n","    def forward(self, x):\n","        return self.fn(x) + x\n","\n","\n","class ConvMixerBlock(nn.Module):\n","    def __init__(self, dim=512, depth=7, k=7):\n","        super(ConvMixerBlock, self).__init__()\n","        self.block = nn.Sequential(\n","            *[nn.Sequential(\n","                Residual(nn.Sequential(\n","                    # deep wise\n","                    nn.Conv2d(dim, dim, kernel_size=(k, k), groups=dim, padding=(k // 2, k // 2)),\n","                    nn.GELU(),\n","                    nn.BatchNorm2d(dim)\n","                )),\n","                nn.Conv2d(dim, dim, kernel_size=(1, 1)),\n","                nn.GELU(),\n","                nn.BatchNorm2d(dim)\n","            ) for i in range(depth)]\n","        )\n","\n","    def forward(self, x):\n","        x = self.block(x)\n","        return x"],"metadata":{"id":"-zYlUc2Ysi7A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"R0Y-1yUp9rYB"}},{"cell_type":"markdown","source":["## Attention U-Net"],"metadata":{"id":"fFbxa69CjjHb"}},{"cell_type":"code","source":["class Attention_UNet(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=2, drop_prob=0):\n","        super(Attention_UNet,self).__init__()\n","\n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","\n","        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n","        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n","        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n","        self.Conv4 = conv_block(ch_in=256,ch_out=512, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","        self.Conv5 = conv_block(ch_in=512,ch_out=1024, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","\n","        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n","        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n","        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n","\n","        self.Up4 = up_conv(ch_in=512,ch_out=256)\n","        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n","        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n","\n","        self.Up3 = up_conv(ch_in=256,ch_out=128)\n","        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n","        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n","\n","        self.Up2 = up_conv(ch_in=128,ch_out=64)\n","        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n","        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n","\n","        self.Conv_1x1 = nn.Sequential(\n","            nn.Conv2d(64, output_ch, kernel_size=1,stride=1,padding=0),\n","            nn.Softmax(dim=1)\n","            )\n","\n","    def forward(self,x):\n","        # encoding path\n","        x1 = self.Conv1(x)\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","\n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","        x4 = self.Att5(d5,x4)\n","        d5 = torch.cat((x4,d5),dim=1)\n","        d5 = self.Up_conv5(d5)\n","\n","        d4 = self.Up4(d5)\n","        x3 = self.Att4(d4,x3)\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(d4)\n","        x2 = self.Att3(d3,x2)\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        x1 = self.Att2(d2,x1)\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","\n","        d1 = self.Conv_1x1(d2)\n","\n","        return d1"],"metadata":{"id":"YrEyEnBmjmgi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Proposed"],"metadata":{"id":"ng3qPvlY9w0S"}},{"cell_type":"code","metadata":{"id":"rI9bdb4CCHxO"},"source":["class SegNet(nn.Module):\n","    def __init__(self, input_channel = 3, in_channel = 32,\n","                 num_classes = 2, drop_prob = 0):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(\n","            ConvBn(input_channel, in_channel),\n","            ConvBn(in_channel, in_channel)\n","        )\n","        grow_list = [16, 32, 64, 64, 64]\n","        repetition_list = [6, 6, 6, 6, 6]\n","        block_list = [5, 4, 3, 2]\n","        ch_decoder = [256, 128, 64, 32]\n","        in_ch_skip = []\n","        self.dense_list = nn.ModuleList()\n","        self.downsample_list = nn.ModuleList()\n","        self.decoder_list = nn.ModuleList()\n","        self.up_sample_list = nn.ModuleList()\n","\n","        for i in range(4):\n","            self.dense_list.append(DenseBlock(in_channel, grow_list[i], repetition_list[i]))\n","            in_channel += repetition_list[i] * grow_list[i]\n","            in_ch_skip.append(in_channel)\n","            self.downsample_list.append(DownSampleBlock(in_channel, block_list[i], drop_prob))\n","            in_channel = in_channel // 2\n","\n","        i+=1\n","        self.bottle_neck = DenseBlock(in_channel, grow_list[i], repetition_list[i])\n","        in_channel += repetition_list[i] * grow_list[i]\n","        for i in range(4):\n","            self.decoder_list.append(DecoderBlock(in_channel, in_ch_skip[-i-1], ch_decoder[i],\n","                                                  block_list[-i-1], drop_prob))\n","            self.up_sample_list.append(UpsampleBlock(in_channel, num_classes, 4-i))\n","            in_channel = ch_decoder[i]\n","        in_channel += 4 * num_classes\n","\n","        self.conv2 = nn.Sequential(\n","            nn.BatchNorm2d(in_channel),\n","            nn.Mish(),\n","            nn.Conv2d(in_channel, num_classes, kernel_size=1, padding=0),\n","            nn.Softmax(dim=1)\n","            )\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        encoder_for_cat = []\n","        output_cat = []\n","        for i in range(4):\n","            x = self.dense_list[i](x)\n","            encoder_for_cat.append(x)\n","            x = self.downsample_list[i](x)\n","        x = self.bottle_neck(x)\n","        #x = self.middle(x)\n","        output_cat.append(self.up_sample_list[0](x))\n","        for i in range(4):\n","            x = self.decoder_list[i](x, encoder_for_cat[-i-1])\n","            if i < 3:\n","                output_cat.append(self.up_sample_list[i+1](x))\n","        output_cat.append(x)\n","        output = torch.cat(output_cat, dim=1)\n","        output = self.conv2(output)\n","\n","        return output\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## draft"],"metadata":{"id":"kEql7Bsw9105"}},{"cell_type":"code","source":["class U_Net_mixer(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=2, drop_prob = 0):\n","        super(U_Net_mixer,self).__init__()\n","\n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","        channel = 64\n","        self.Conv1 = conv_block(ch_in=img_ch,ch_out=channel)\n","        self.Conv2 = conv_block(ch_in=channel,ch_out=channel*2)\n","        self.Conv3 = conv_block(ch_in=channel*2,ch_out=channel*4)\n","        self.Conv4 = conv_block(ch_in=channel*4,ch_out=channel*8, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","        self.Conv5 = conv_block(ch_in=channel*8,ch_out=channel*16, drop_block=True, block_size = 3, drop_prob = drop_prob)\n","\n","        self.middle = ConvMixer(channel*16, 1, 9, 7)\n","\n","        self.Up5 = up_conv(ch_in=channel*16,ch_out=channel*8)\n","        self.Up_conv5 = conv_block(ch_in=channel*16, ch_out=channel*8)\n","\n","        self.Up4 = up_conv(ch_in=channel*8,ch_out=channel*4)\n","        self.Up_conv4 = conv_block(ch_in=channel*8, ch_out=channel*4)\n","\n","        self.Up3 = up_conv(ch_in=channel*4,ch_out=channel*2)\n","        self.Up_conv3 = conv_block(ch_in=channel*4, ch_out=channel*2)\n","\n","        self.Up2 = up_conv(ch_in=channel*2,ch_out=channel)\n","        self.Up_conv2 = conv_block(ch_in=channel*2, ch_out=channel)\n","\n","        self.Conv_1x1 = nn.Sequential(\n","            nn.Conv2d(channel, output_ch,kernel_size=1,stride=1,padding=0),\n","            nn.Softmax(dim=1)\n","            )\n","\n","\n","    def forward(self,x):\n","        # encoding path\n","        x1 = self.Conv1(x)\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","\n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","\n","        #x5 = self.middle(x5)\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","        d5 = torch.cat((x4,d5),dim=1)\n","        d5 = self.Up_conv5(d5)\n","\n","        d4 = self.Up4(d5)\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(d4)\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","\n","        d1 = self.Conv_1x1(d2)\n","\n","        return d1"],"metadata":{"id":"8iBp5Sm493_G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Modified PiDiNet"],"metadata":{"id":"XpwYPFZij5Na"}},{"cell_type":"code","source":["class CSAM(nn.Module):\n","    \"\"\"\n","    Compact Spatial Attention Module\n","    \"\"\"\n","    def __init__(self, channels):\n","        super(CSAM, self).__init__()\n","\n","        mid_channels = 4\n","        self.relu1 = nn.ReLU()\n","        self.conv1 = nn.Conv2d(channels, mid_channels, kernel_size=1, padding=0)\n","        self.conv2 = nn.Conv2d(mid_channels, 1, kernel_size=3, padding=1, bias=False)\n","        self.sigmoid = nn.Sigmoid()\n","        nn.init.constant_(self.conv1.bias, 0)\n","\n","    def forward(self, x):\n","        y = self.relu1(x)\n","        y = self.conv1(y)\n","        y = self.conv2(y)\n","        y = self.sigmoid(y)\n","\n","        return x * y\n","\n","class CDCM(nn.Module):\n","    \"\"\"\n","    Compact Dilation Convolution based Module\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels):\n","        super(CDCM, self).__init__()\n","\n","        self.relu1 = nn.ReLU()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)\n","        self.conv2_1 = nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=5, padding=5, bias=False)\n","        self.conv2_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=7, padding=7, bias=False)\n","        self.conv2_3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=9, padding=9, bias=False)\n","        self.conv2_4 = nn.Conv2d(out_channels, out_channels, kernel_size=3, dilation=11, padding=11, bias=False)\n","        nn.init.constant_(self.conv1.bias, 0)\n","\n","    def forward(self, x):\n","        x = self.relu1(x)\n","        x = self.conv1(x)\n","        x1 = self.conv2_1(x)\n","        x2 = self.conv2_2(x)\n","        x3 = self.conv2_3(x)\n","        x4 = self.conv2_4(x)\n","        return x1 + x2 + x3 + x4\n","\n","class MapReduce(nn.Module):\n","    \"\"\"\n","    Reduce feature maps into a single edge map\n","    \"\"\"\n","    def __init__(self, channels):\n","        super(MapReduce, self).__init__()\n","        self.conv = nn.Conv2d(channels, 2, kernel_size=1, padding=0)\n","        nn.init.constant_(self.conv.bias, 0)\n","\n","    def forward(self, x):\n","        return self.conv(x)"],"metadata":{"id":"-pB0UcKwpGaA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PiDiNet(nn.Module):\n","    def __init__(self, img_channel=3, inplane=32, num_classes=2, dil=8, sa=True, ta=True, drop_prob = 0, msag = True, csag = True): #dil=None, sa=False; inplane luc dau muon depth tu 3 len 32/64, pdcs\n","        super(PiDiNet, self).__init__()\n","        self.sa = sa\n","        self.ta = ta\n","        self.msag = msag\n","        self.csag = csag\n","        if dil is not None:\n","            assert isinstance(dil, int), 'dil should be an int'\n","        self.dil = dil\n","\n","        self.fuseplanes = []\n","\n","        self.inplane = inplane\n","        self.img_channel = img_channel\n","        self.num_classes = num_classes\n","        self.drop_prob = drop_prob\n","\n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","        self.Conv5 = conv_block(ch_in=self.inplane*8,ch_out=self.inplane*16, drop_block=True, block_size = 3, drop_prob = self.drop_prob)\n","        self.middle_1 = conv_stem(inplane=self.inplane*16, outplane=self.inplane*16, patch_size=1)\n","        self.middle_2 = ConvMixer(inplane=self.inplane*16, kernels_per_layer=1, outplane=self.inplane*16, kernels_size=5)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","        self.init_block = nn.Conv2d(self.img_channel, self.inplane, kernel_size=3, padding=1) #x1->32\n","        self.aspp = PASPP(self.inplane*16,self.inplane*16,16)\n","\n","        self.Conv1 = conv_block(ch_in=self.img_channel,ch_out=self.inplane)\n","        self.Up2 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att2 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv2 = conv_block(ch_in=self.inplane*2, ch_out=self.inplane)\n","        self.fuseplanes.append(self.inplane) # C\n","        #ours\n","        self.msag1 = MSAG(self.inplane)\n","        self.csag1 = CSAG(channel1 = self.inplane, channel2 = self.img_channel)\n","        self.mixer1 = ConvMixerBlock(dim = self.inplane, depth = 1)\n","\n","        inplane = self.inplane\n","        self.inplane = self.inplane * 2 #x2->64\n","        self.Conv2 = conv_block(ch_in=self.inplane//2,ch_out=self.inplane)\n","        self.Up3 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att3 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv3 = conv_block(ch_in=self.inplane*2, ch_out=self.inplane)\n","        self.fuseplanes.append(self.inplane) # 2C\n","        #ours\n","        self.msag2 = MSAG(self.inplane)\n","        self.csag2 = CSAG(channel1 = self.inplane, channel2 = self.inplane//2)\n","        self.mixer2 = ConvMixerBlock(dim = self.inplane, depth = 1)\n","\n","\n","        inplane = self.inplane\n","        self.inplane = self.inplane * 2 #x4->128\n","        self.Conv3 = conv_block(ch_in=self.inplane//2,ch_out=self.inplane)\n","        self.Up4 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att4 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv4 = conv_block(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.fuseplanes.append(self.inplane) # 4C\n","        #ours\n","        self.msag3 = MSAG(self.inplane)\n","        self.csag3 = CSAG(channel1 = self.inplane, channel2 = self.inplane//2)\n","        self.mixer3 = ConvMixerBlock(dim = self.inplane, depth = 1)\n","\n","        inplane = self.inplane\n","        self.inplane = self.inplane * 2 #x8->256\n","        self.Conv4 = conv_block(ch_in=self.inplane//2,ch_out=self.inplane, drop_block=True, block_size = 5, drop_prob = self.drop_prob)\n","        self.Up5 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att5 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv5 = conv_block(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.fuseplanes.append(self.inplane) # 8C\n","        #ours\n","        self.csag4 = CSAG(channel1 = self.inplane, channel2 = self.inplane//2)\n","        self.msag4 = MSAG(self.inplane)\n","        self.mixer4 = ConvMixerBlock(dim = self.inplane, depth = 1)\n","\n","        #Conv-Mixer\n","        self.convmixer = ConvMixerBlock(dim = self.inplane*2)\n","\n","        self.conv_reduces = nn.ModuleList()\n","        if self.sa and self.dil is not None:\n","            self.attentions = nn.ModuleList()\n","            self.dilations = nn.ModuleList()\n","            for i in range(4):\n","                self.dilations.append(CDCM(self.fuseplanes[i], self.dil))\n","                self.attentions.append(CSAM(self.dil))\n","                self.conv_reduces.append(MapReduce(self.dil))\n","        elif self.sa:\n","            self.attentions = nn.ModuleList()\n","            for i in range(4):\n","                self.attentions.append(CSAM(self.fuseplanes[i]))\n","                self.conv_reduces.append(MapReduce(self.fuseplanes[i]))\n","        elif self.dil is not None:\n","            self.dilations = nn.ModuleList()\n","            for i in range(4):\n","                self.dilations.append(CDCM(self.fuseplanes[i], self.dil))\n","                self.conv_reduces.append(MapReduce(self.dil))\n","        else:\n","            for i in range(4):\n","                self.conv_reduces.append(MapReduce(self.fuseplanes[i]))\n","\n","        #self.classifier = nn.Conv2d(4, 1, kernel_size=1)\n","        self.classifier = nn.Sequential(\n","            nn.Conv2d(8, self.num_classes, kernel_size=1,stride=1,padding=0), nn.Softmax(dim=1))\n","        #nn.init.constant_(self.classifier.weight, 0.25)\n","        #nn.init.constant_(self.classifier.bias, 0)\n","\n","        print('initialization done')\n","\n","    def get_weights(self):\n","        conv_weights = []\n","        bn_weights = []\n","        relu_weights = []\n","        for pname, p in self.named_parameters():\n","            if 'bn' in pname:\n","                bn_weights.append(p)\n","            elif 'relu' in pname:\n","                relu_weights.append(p)\n","            else:\n","                conv_weights.append(p)\n","\n","        return conv_weights, bn_weights, relu_weights\n","\n","    def forward(self, x):\n","        H, W = x.size()[2:]\n","        #x = self.init_block(x)\n","        # encoding path\n","        x1 = self.Conv1(x)\n","        x1_1 = x1\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","        x2_1 = x2\n","\n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","        x3_1 = x3\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","        x4_1 = x4\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","        x5_1 = x5\n","\n","\n","        #Conv-Mixer\n","        x5 = self.convmixer(x5)\n","        print(x5.shape)\n","        x5 = self.middle_1(x5)\n","        x5 = self.middle_2(x5)\n","\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","        #Proposed Attention\n","        if self.ta:\n","            x4 = self.Att5(d5,x4)\n","        if self.csag:\n","            x4 = self.csag4(x3, x4, x5)\n","        if self.msag:\n","            x4 = self.msag4(x4)\n","\n","        d5 = torch.cat((x4,d5),dim=1)\n","        d5 = self.Up_conv5(d5)\n","        d5 = self.mixer4(d5)\n","        d4 = self.Up4(d5)\n","\n","        #Proposed Attention\n","        if self.ta:\n","            x3 = self.Att4(d4,x3)\n","        if self.csag:\n","            x3 = self.csag3(x2, x3, x4)\n","        if self.msag:\n","            x3 = self.msag3(x3)\n","\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","        d4 = self.mixer3(d4)\n","        d3 = self.Up3(d4)\n","        #Proposed Attention\n","        if self.ta:\n","            x2 = self.Att3(d3,x2)\n","        if self.csag:\n","            x2 = self.csag2(x1, x2, x3)\n","        if self.msag:\n","            x2 = self.msag2(x2)\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","        d3 = self.mixer2(d3)\n","        d2 = self.Up2(d3)\n","        #Proposed Attention\n","        if self.ta:\n","            x1 = self.Att2(d2,x1)\n","        if self.csag:\n","            x1 = self.csag1(x, x1, x2)\n","        if self.msag:\n","            x1 = self.msag1(x1)\n","\n","        #\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","        d2 = self.mixer1(d2)\n","        x_fuses = []\n","        if self.sa and self.dil is not None:\n","            for i, xi in enumerate([d2,d3,d4,d5]):\n","                x_fuses.append(self.attentions[i](self.dilations[i](xi)))\n","        elif self.sa:\n","            for i, xi in enumerate([d2,d3,d4,d5]):\n","                x_fuses.append(self.attentions[i](xi))\n","        elif self.dil is not None:\n","            for i, xi in enumerate([d2,d3,d4,d5]):\n","                x_fuses.append(self.dilations[i](xi))\n","        else:\n","            x_fuses = [d2,d3,d4,d5]\n","\n","        e1 = self.conv_reduces[0](x_fuses[0])\n","        e1 = F.interpolate(e1, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        e2 = self.conv_reduces[1](x_fuses[1])\n","        e2 = F.interpolate(e2, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        e3 = self.conv_reduces[2](x_fuses[2])\n","        e3 = F.interpolate(e3, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        e4 = self.conv_reduces[3](x_fuses[3])\n","        e4 = F.interpolate(e4, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        outputs = [e1, e2, e3, e4]\n","\n","        output = self.classifier(torch.cat(outputs, dim=1))\n","\n","        output = self.softmax(output)\n","        return output\n","\n"],"metadata":{"id":"Ow1ZF-Byj8Uj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.rand(1,3,192,256)\n","conv_stem1 = conv_stem(512,51,1)\n","model = PiDiNet()\n","print(model(x).shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qmzm9CaQQF4p","executionInfo":{"status":"ok","timestamp":1682826518700,"user_tz":-420,"elapsed":1323,"user":{"displayName":"Vu Hung","userId":"02978926439125713005"}},"outputId":"0d64eef7-b780-4ef3-e674-d2cd2ae05cb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["initialization done\n","torch.Size([1, 512, 12, 16])\n","torch.Size([1, 2, 192, 256])\n"]}]},{"cell_type":"markdown","source":["#Hope Net for last version\n"],"metadata":{"id":"FmO2IHUAP2Pi"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MHSA(nn.Module):\n","    def __init__(self, n_dims, width=14, height=14, heads=4):\n","        super(MHSA, self).__init__()\n","        self.heads = heads\n","\n","        self.query = nn.Conv2d(n_dims, n_dims, kernel_size=1)\n","        self.key = nn.Conv2d(n_dims, n_dims, kernel_size=1)\n","        self.value = nn.Conv2d(n_dims, n_dims, kernel_size=1)\n","\n","        self.rel_h = nn.Parameter(torch.randn([1, heads, n_dims // heads, 1, height]), requires_grad=True)\n","        self.rel_w = nn.Parameter(torch.randn([1, heads, n_dims // heads, width, 1]), requires_grad=True)\n","\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.norm = nn.LayerNorm([n_dims, width, height])\n","\n","    def forward(self, x):\n","        n_batch, C, width, height = x.size()\n","        q = self.query(x).view(n_batch, self.heads, C // self.heads, -1)\n","        k = self.key(x).view(n_batch, self.heads, C // self.heads, -1)\n","        v = self.value(x).view(n_batch, self.heads, C // self.heads, -1)\n","\n","        content_content = torch.matmul(q.permute(0, 1, 3, 2), k)\n","\n","        content_position = (self.rel_h + self.rel_w).view(1, self.heads, C // self.heads, -1).permute(0, 1, 3, 2)\n","        content_position = torch.matmul(content_position, q)\n","\n","        energy = content_content + content_position\n","        attention = self.softmax(energy)\n","\n","        out = torch.matmul(v, attention.permute(0, 1, 3, 2))\n","        out = out.view(n_batch, C, width, height)\n","        out = self.norm(out) + x\n","        return out"],"metadata":{"id":"o83OB0maP4nV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CSAG(nn.Module):\n","\n","    def __init__(self, channel1, channel2):\n","        super(CSAG, self).__init__()\n","        self.channel2 = channel2\n","        self.upsample_layer = nn.ConvTranspose2d(in_channels=channel1*2, out_channels=channel1, kernel_size=2, stride=2, padding=0)\n","        nn.init.constant_(self.upsample_layer.bias, 0)\n","\n","        self.conv_up = nn.Conv2d(channel2, channel1, kernel_size=2, padding=0, stride = 2)\n","        self.conv_up_input = nn.Conv2d(channel2, channel1, kernel_size=1, padding=0)\n","        nn.init.constant_(self.conv_up.bias, 0)\n","        self.conv_end = nn.Conv2d(channel1*3, channel1, kernel_size=1, padding=0)\n","    def forward(self, x1, x2, x3):\n","        x3 = self.upsample_layer(x3)\n","\n","        if self.channel2 == 3:\n","            x1 = self.conv_up_input(x1)\n","        else:\n","            x1 = self.conv_up(x1)\n","        out = [x1, x2, x3]\n","        out = torch.cat(out, dim=1)\n","        out = self.conv_end(out)\n","        return out"],"metadata":{"id":"_KztkdEFjXam"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","\n","\n","class MSAG(nn.Module):\n","    \"\"\"\n","    Multi-scale attention gate\n","    \"\"\"\n","    def __init__(self, channel):\n","        super(MSAG, self).__init__()\n","        self.channel = channel\n","        self.pointwiseConv = nn.Sequential(\n","            nn.Conv2d(self.channel, self.channel, kernel_size=1, padding=0, bias=True),\n","            nn.BatchNorm2d(self.channel),\n","        )\n","        self.ordinaryConv = nn.Sequential(\n","            nn.Conv2d(self.channel, self.channel, kernel_size=3, padding=1, stride=1, bias=True),\n","            nn.BatchNorm2d(self.channel),\n","        )\n","        self.dilationConv = nn.Sequential(\n","            nn.Conv2d(self.channel, self.channel, kernel_size=3, padding=2, stride=1, dilation=2, bias=True),\n","            nn.BatchNorm2d(self.channel),\n","        )\n","        self.voteConv = nn.Sequential(\n","            nn.Conv2d(self.channel * 3, self.channel, kernel_size=(1, 1)),\n","            nn.BatchNorm2d(self.channel),\n","            nn.Sigmoid()\n","        )\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        x1 = self.pointwiseConv(x)\n","        x2 = self.ordinaryConv(x)\n","        x3 = self.dilationConv(x)\n","        _x = self.relu(torch.cat((x1, x2, x3), dim=1))\n","        _x = self.voteConv(_x)\n","        x = x + x * _x\n","        return x"],"metadata":{"id":"4HFmt7mFXrVW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Hope_Net(nn.Module):\n","    def __init__(self, img_channel=3, inplane=32, num_classes=2, dil=8, sa=True, ta=False, drop_prob = 0, mhsa = True, csag = True): #dil=None, sa=False; inplane luc dau muon depth tu 3 len 32/64, pdcs\n","        super(Hope_Net, self).__init__()\n","        self.sa = sa\n","        self.ta = ta\n","        self.csag = csag\n","        self.mhsa = mhsa\n","        if dil is not None:\n","            assert isinstance(dil, int), 'dil should be an int'\n","        self.dil = dil\n","\n","        self.fuseplanes = []\n","\n","        self.inplane = inplane\n","        self.img_channel = img_channel\n","        self.num_classes = num_classes\n","        self.drop_prob = drop_prob\n","\n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","        self.Conv5 = conv_block(ch_in=self.inplane*8,ch_out=self.inplane*16, drop_block=True, block_size = 3, drop_prob = self.drop_prob)\n","        self.middle_1 = conv_stem(inplane=self.inplane*16, outplane=self.inplane*16, patch_size=2)\n","        self.middle_2 = ConvMixer(inplane=self.inplane*16, kernels_per_layer=1, outplane=self.inplane*16, kernels_size=5)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","        self.init_block = nn.Conv2d(self.img_channel, self.inplane, kernel_size=3, padding=1) #x1->32\n","        self.aspp = PASPP(self.inplane*16,self.inplane*16,16)\n","\n","        self.Conv1 = conv_block(ch_in=self.img_channel,ch_out=self.inplane)\n","        self.Up2 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att2 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv2 = conv_block(ch_in=self.inplane*2, ch_out=self.inplane)\n","        self.fuseplanes.append(self.inplane) # C\n","        #ours\n","        self.csag1 = CSAG(channel1 = self.inplane, channel2 = self.img_channel)\n","        self.mixer1 = ConvMixerBlock(dim = self.inplane, depth = 1)\n","\n","        self.msag1 = MSAG(self.inplane)\n","\n","        inplane = self.inplane\n","        self.inplane = self.inplane * 2 #x2->64\n","        self.Conv2 = conv_block(ch_in=self.inplane//2,ch_out=self.inplane)\n","        self.Up3 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att3 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv3 = conv_block(ch_in=self.inplane*2, ch_out=self.inplane)\n","        self.fuseplanes.append(self.inplane) # 2C\n","        #ours\n","        self.csag2 = CSAG(channel1 = self.inplane, channel2 = self.inplane//2)\n","        self.mixer2 = ConvMixerBlock(dim = self.inplane, depth = 1)\n","\n","        self.msag2 = MSAG(self.inplane)\n","\n","        inplane = self.inplane\n","        self.inplane = self.inplane * 2 #x4->128\n","        self.Conv3 = conv_block(ch_in=self.inplane//2,ch_out=self.inplane)\n","        self.Up4 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att4 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv4 = conv_block(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.fuseplanes.append(self.inplane) # 4C\n","        #ours\n","        self.csag3 = CSAG(channel1 = self.inplane, channel2 = self.inplane//2)\n","        self.mixer3 = ConvMixerBlock(dim = self.inplane, depth = 1)\n","\n","        self.msag3 = MSAG(self.inplane)\n","\n","        inplane = self.inplane\n","        self.inplane = self.inplane * 2 #x8->256\n","        self.Conv4 = conv_block(ch_in=self.inplane//2,ch_out=self.inplane, drop_block=True, block_size = 5, drop_prob = self.drop_prob)\n","        self.Up5 = up_conv(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.Att5 = Attention_block(F_g=self.inplane,F_l=self.inplane,F_int=self.inplane//2)\n","        self.Up_conv5 = conv_block(ch_in=self.inplane*2,ch_out=self.inplane)\n","        self.fuseplanes.append(self.inplane) # 8C\n","        #ours\n","        self.csag4 = CSAG(channel1 = self.inplane, channel2 = self.inplane//2)\n","        self.mixer4 = ConvMixerBlock(dim = self.inplane, depth = 1)\n","\n","        self.msag4 = MSAG(self.inplane)\n","        #Conv-Mixer\n","        self.convmixer = ConvMixerBlock(dim = self.inplane*2)\n","        self.mhsa = MHSA(n_dims = 512, width=12, height=16, heads=4)\n","\n","        self.conv_reduces = nn.ModuleList()\n","        if self.sa and self.dil is not None:\n","            self.attentions = nn.ModuleList()\n","            self.dilations = nn.ModuleList()\n","            for i in range(4):\n","                self.dilations.append(CDCM(self.fuseplanes[i], self.dil))\n","                self.attentions.append(CSAM(self.dil))\n","                self.conv_reduces.append(MapReduce(self.dil))\n","        elif self.sa:\n","            self.attentions = nn.ModuleList()\n","            for i in range(4):\n","                self.attentions.append(CSAM(self.fuseplanes[i]))\n","                self.conv_reduces.append(MapReduce(self.fuseplanes[i]))\n","        elif self.dil is not None:\n","            self.dilations = nn.ModuleList()\n","            for i in range(4):\n","                self.dilations.append(CDCM(self.fuseplanes[i], self.dil))\n","                self.conv_reduces.append(MapReduce(self.dil))\n","        else:\n","            for i in range(4):\n","                self.conv_reduces.append(MapReduce(self.fuseplanes[i]))\n","\n","        #self.classifier = nn.Conv2d(4, 1, kernel_size=1)\n","        self.classifier = nn.Sequential(\n","            nn.Conv2d(8, self.num_classes, kernel_size=1,stride=1,padding=0), nn.Softmax(dim=1))\n","        #nn.init.constant_(self.classifier.weight, 0.25)\n","        #nn.init.constant_(self.classifier.bias, 0)\n","\n","        print('initialization done')\n","\n","    def get_weights(self):\n","        conv_weights = []\n","        bn_weights = []\n","        relu_weights = []\n","        for pname, p in self.named_parameters():\n","            if 'bn' in pname:\n","                bn_weights.append(p)\n","            elif 'relu' in pname:\n","                relu_weights.append(p)\n","            else:\n","                conv_weights.append(p)\n","\n","        return conv_weights, bn_weights, relu_weights\n","\n","    def forward(self, x):\n","        H, W = x.size()[2:]\n","\n","        # encoding path\n","        #Layer 1\n","        x1 = self.Conv1(x)\n","\n","        #Layer 2\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","\n","        #Layer 3\n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        #Layer 4\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        #Layer 5\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","\n","\n","\n","        #Transformer\n","        #x5 = self.convmixer(x5)\n","        X5 = self.mhsa(x5)\n","\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","\n","        #Proposed Attention\n","        if self.ta:\n","            x4 = self.Att5(d5,x4)\n","        if self.csag:\n","            x4 = self.csag4(x3, x4, x5)\n","        if self.mhsa:\n","            x4 = self.msag4(x4)\n","\n","        d5 = torch.cat((x4,d5),dim=1)\n","        d5 = self.Up_conv5(d5)\n","        d5 = self.mixer4(d5)\n","\n","        d4 = self.Up4(d5)\n","\n","        #Proposed Attention\n","        if self.ta:\n","            x3 = self.Att4(d4,x3)\n","        if self.csag:\n","            x3 = self.csag3(x2, x3, d5)\n","        if self.mhsa:\n","            x3 = self.msag3(x3)\n","\n","\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","        d4 = self.mixer3(d4)\n","        d3 = self.Up3(d4)\n","        #Proposed Attention\n","        if self.ta:\n","            x2 = self.Att3(d3,x2)\n","        if self.csag:\n","            x2 = self.csag2(x1, x2, d4)\n","        if self.mhsa:\n","            x2 = self.msag2(x2)\n","\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","        d3 = self.mixer2(d3)\n","        d2 = self.Up2(d3)\n","        #Proposed Attention\n","        if self.ta:\n","            x1 = self.Att2(d2,x1)\n","        if self.csag:\n","            x1 = self.csag1(x, x1, d3)\n","        if self.mhsa:\n","            x1 = self.msag1(x1)\n","\n","        #\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","        d2 = self.mixer1(d2)\n","        x_fuses = []\n","        if self.sa and self.dil is not None:\n","            for i, xi in enumerate([d2,d3,d4,d5]):\n","                x_fuses.append(self.attentions[i](self.dilations[i](xi)))\n","        elif self.sa:\n","            for i, xi in enumerate([d2,d3,d4,d5]):\n","                x_fuses.append(self.attentions[i](xi))\n","        elif self.dil is not None:\n","            for i, xi in enumerate([d2,d3,d4,d5]):\n","                x_fuses.append(self.dilations[i](xi))\n","        else:\n","            x_fuses = [d2,d3,d4,d5]\n","\n","        e1 = self.conv_reduces[0](x_fuses[0])\n","        e1 = F.interpolate(e1, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        e2 = self.conv_reduces[1](x_fuses[1])\n","        e2 = F.interpolate(e2, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        e3 = self.conv_reduces[2](x_fuses[2])\n","        e3 = F.interpolate(e3, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        e4 = self.conv_reduces[3](x_fuses[3])\n","        e4 = F.interpolate(e4, (H, W), mode=\"bilinear\", align_corners=False)\n","\n","        outputs = [e1, e2, e3, e4]\n","\n","        output = self.classifier(torch.cat(outputs, dim=1))\n","\n","        output = self.softmax(output)\n","        return output\n","\n"],"metadata":{"id":"WK8Tu51aSRya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#x = torch.rand(1,3,192,256)\n","#model = Hope_Net()\n","#print(model(x).shape)\n"],"metadata":{"id":"k2nIlPXUTSjR"},"execution_count":null,"outputs":[]}]}